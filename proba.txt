test starts with:  True
appoved link  https://www.dataminded.com
appoved link  https://www.dataminded.com/consulting
appoved link  https://www.dataminded.com/conveyor
appoved link  https://www.dataminded.com/conveyor-product-and-features
appoved link  https://www.dataminded.com/conveyor-vs-diy
appoved link  https://www.dataminded.com/conveyor-pricing
appoved link  https://www.dataminded.com/conveyor-contact
appoved link  https://www.dataminded.com/academy
appoved link  https://www.dataminded.com/data-engineering-manifesto
appoved link  https://www.dataminded.com/dmi
appoved link  https://www.dataminded.com/cases
appoved link  https://www.dataminded.com/webinars
appoved link  https://www.dataminded.com/team
appoved link  https://www.dataminded.com/join-us
appoved link  https://www.dataminded.com/cloud-partnerships
appoved link  https://www.dataminded.com/data-engineers
appoved link  https://www.dataminded.com/cases/bics
appoved link  https://www.dataminded.com/cases/
appoved link  https://www.dataminded.com/cases/luminus
appoved link  https://www.dataminded.com/cases/dpg
appoved link  https://www.dataminded.com/cases/newpharma
appoved link  https://www.dataminded.com/cases/kwarts
appoved link  https://www.dataminded.com/conveyor-vs-databrics
appoved link  https://www.dataminded.com/conveyor-vs-emr
appoved link  https://www.dataminded.com/data-foundations
appoved link  https://www.dataminded.com/data-democratization
appoved link  https://www.dataminded.com/mlops
appoved link  https://www.dataminded.com/cases/luminus-neo
 Consulting Conveyor Academy Resources About us More Build sustainable and scalable data organisations that deliver on the promise of data and AI We are passionated about data engineering. We guide and deliver complex data projects through their entire lifecycle, from idea to production. 57 clients 138 data initiatives delivered 400+ people trained 200+ Conveyor projects Our consulting services include architecting and developing cloud-native data platforms, data pipelines and analytical applications.  Conveyor is a managed data engineering platform for building and running secure and reliable data products.  We help individuals and teams become better at data engineering. We co-create insights, skills and strong teams through online and offline training.  Understanding the ambitions and the current data maturity level is crucial before starting or continuing your data journey. Therefore Data Minded developed a Data Maturity Index that helps you visualize the balance in your data organization. Not only is the Data Maturity Index helpful to focus on the actual bottlenecks and set priorities, it also is a benchmark to visualize the impact of engagements and transformations. Offer new products and insights as a service and tap into new business opportunities. Increase productivity within your business and reduce lead times and costs. Stimulate exploration and scale for sustainable value creation. Facilitate cross-domain collaboration through data and reduce risk. Consulting Conveyor Product & Features Comparison Docs Academy Our offering Resources Cases Blog About us Team Join us Cloud Partnerships Pricing Vismarkt 17, 3000 Leuven, Belgium info@dataminded.be Vat. BE.0667.976.246 Consulting Conveyor Academy Resources About us More Build sustainable and scalable data organisations that deliver on the promise of data and AI We are passionated about data engineering. We guide and deliver complex data projects through their entire lifecycle, from idea to production. 57 clients 138 data initiatives delivered 400+ people trained 200+ Conveyor projects Our consulting services include architecting and developing cloud-native data platforms, data pipelines and analytical applications.  Conveyor is a managed data engineering platform for building and running secure and reliable data products.  We help individuals and teams become better at data engineering. We co-create insights, skills and strong teams through online and offline training.  Understanding the ambitions and the current data maturity level is crucial before starting or continuing your data journey. Therefore Data Minded developed a Data Maturity Index that helps you visualize the balance in your data organization. Not only is the Data Maturity Index helpful to focus on the actual bottlenecks and set priorities, it also is a benchmark to visualize the impact of engagements and transformations. Offer new products and insights as a service and tap into new business opportunities. Increase productivity within your business and reduce lead times and costs. Stimulate exploration and scale for sustainable value creation. Facilitate cross-domain collaboration through data and reduce risk. Consulting Conveyor Product & Features Comparison Docs Academy Our offering Resources Cases Blog About us Team Join us Cloud Partnerships Pricing Vismarkt 17, 3000 Leuven, Belgium info@dataminded.be Vat. BE.0667.976.246 Consulting Conveyor Academy Resources About us More Data Minded Consulting covers a wide range of services that are developed to support our clients in every phase and area of their journey into data. Our services cross three wide areas Strategy Engineering Operations Get a taste for business value Scale to efficiently build new use cases Empower everyone to use data Consulting Conveyor Product & Features Comparison Docs Academy Our offering Resources Cases Blog About us Team Join us Cloud Partnerships Pricing Vismarkt 17, 3000 Leuven, Belgium info@dataminded.be Vat. BE.0667.976.246 Consulting Conveyor Academy Resources About us More Conveyor unites an entire ecosystem of modern tools and services into a single, simple workflow for building maintainable and cost effective data projects. Templates for various technologies and use case, get you started with just a couple of key strokes. Using the remote execution `run` command, you can execute your code remotely in the right context. Find out more about how Conveyor works Get started with a single command.
Scaffold your batch or stream processing project from one of our templates following industry best practices.
  Choose your compute size and deploy in seconds.
Use T-shirt sizing to select the appropriate size for the workload. Deploy to test and promote to production.
  Extend your use-cases with your own tools and libraries.
Containerization is at the core. Fit it in a container and run it. Easy journey from notebooks to production.
Embedded notebooks run in the same context as the project sharing code, environment and permissions. This enables using notebooks to debug and facilitates iterative industrialization of experiments. ​ Experiment and test in isolated environments.
Spin up new environments in seconds and avoid impacting your colleagues. Each environment comes with a dedicated workflow manager.
  Metrics and logs, out of the box.
Track performance and errors with live access to metrics and logs. Analyse cost per project.
With cost monitoring, you get insight into the most expensive data projects. Optimize where there is most to gain.
  Default to spot.
Using spot results in typical savings of 70-90% over on-demand pricing. Critical workloads can be configured to run on-demand, or mixed to get the best of both worlds.
  Fully managed.
Services and infrastructure are always up-to-date. No patching, no management, no worries. 37 projects - 53 users "Introducing new technologies and cloud adoption in data & analytics is a challenge, but getting IT and business on the same page can be an even bigger challenge. Working with Conveyor helps in managing the full ecosystem, it accelerates the scaling and it supports collaboration allowing data engineers and data scientists to focus on creating value with new data products, without having to worry too much about some of the underlying complexities of running a scalable data infrastructure in the cloud." Cristiana Pompei
IT Deputy Director Application Delivery at Luminus Run any workload that can be wrapped in a container at any scale. This standardizes the work across data engineers, data scientists and data analysts. Conveyor is adopted by organizations in various industries. Proud to be part of their data journeys and see them grow. Consulting Conveyor Product & Features Comparison Docs Academy Our offering Resources Cases Blog About us Team Join us Cloud Partnerships Pricing Vismarkt 17, 3000 Leuven, Belgium info@dataminded.be Vat. BE.0667.976.246 Consulting Conveyor Academy Resources About us More Cloud providers like AWS, Azure and GCP provide an overwhelming amount of great building blocks. When delivering data projects for our customers, we noticed the proposed stacks often:
  require a lot of glue code, resulting in workable yet sub-optimal user experiences aren’t actively encouraging software engineering practices require a steep learning curve to configure for your needs ​ In our opinion, one of the key dimensions for a better solution is high affinity with software engineering best-practices. Software engineering best-practices and automation leading to smooth deliveries are what make digital winners what they are today. ​ By using containers as the main medium to share softwares with the execution environments, software engineering best-practices and CICD are easier to put in place. So we created a k8s-based, multi-cloud, multi-cluster productivity tool build by developers for developers. End-users interact with Conveyor through a command-line interface (CLI) and a web-based user interface (UI). The CLI is used throughout the building and deploying of data projects, while the UI is mostly used in the run phase. ​ The control plane is hosted by Data Minded. It is middleware between the users and the data plane. It is responsible for cross cutting concerns like user authentication and authorization, state management, cost aggregation, ... . ​ The data plane is the Kubernetes-based managed infrastructure that runs within your own cloud environment. It consists of multiple services that takes care of provisioning and scaling the needed infrastructure and everything related to the scheduling of the execution of data projects. Conveyor has two simple concepts: projects and environments. A project is code, a unit of deployment (architectural quantum) that describes the what and how it needs to be executed.   Environments are isolated segments in the infrastructure where a data project can be deployed and executed. Create a batch pipeline often used for analytics to periodically collect, transform and move data to a data warehouse according to business needs. Templates for various technologies and use case, get you started with just a couple of key strokes. Using the remote execution `run` command, you can execute your code remotely in the right context. Create persistent or throw-away environment. Select a resource size and a security context. Deploy and promote data project with ease. Once your data project is deployed, you want to follow-up on resource utilization, cost and troubleshoot potential failures. An environments links to a Kubernetes clusters deployed as part of the customers data plane. Customers can have multiple clusters spread over homogeneous or heterogenous cloud accounts. Create paved roads, take care of boilerplate and encourage the use of best practices across teams. Clients can create their own templates based on their needs, and the systems they integrate with. Jupyter notebooks are well known for their ease in data exploration and experimentation. Data Minded cloud notebooks are build on the same containerization foundation as data project code. This enables other use cases e.g. using notebooks to debug and facilitate iterative industrialization of experiments. Each environment has a dedicated Apache Airflow instance for batch workload orchestration. Automated client-side DAG validation. Some projects need more power that can be provided by a single node. Data Minded Cloud offers Apache Spark (batch and streaming) as a first class citizen. To operate data projects, logs and metrics are centralized and available in real-time. For some integrations, access to the technology native UIs are available e.g. Apache Spark History Server. Follow your cloud cost per project over time. Gain insight into cost distribution across projects and environments. Authenticate users with your own identity provider. Control the actions any user can perform on projects and environments using role-based mechanisms. Each project can be linked with cloud specific IAM credentials. This link is enforced so that each job can only access those resources it was granted access to. Combined with the RBAC model on environment and projects, data access management is in your hands. Consulting Conveyor Product & Features Comparison Docs Academy Our offering Resources Cases Blog About us Team Join us Cloud Partnerships Pricing Vismarkt 17, 3000 Leuven, Belgium info@dataminded.be Vat. BE.0667.976.246 Consulting Conveyor Academy Resources About us More One of the first things that comes to mind to enable a team of data engineers and data scientists is to build your own data platform. Let us have a look at the pros and cons of that approach and how Conveyor can bring a fresh point of view to this subject. So you are about to start a new data project. They come in different shapes, but often, they resemble one of the following scenarios: ​Data pipelines, Machine learning, Data warehouse modernization. Each scenario requires you to build the data project itself and all the underlying infrastructure. From source control, to packaging and publishing your code, all the way to deployment, scheduling, and operations (logs, metrics, documentation, ...). Create a batch pipeline often used for analytics to periodically collect, transform and move data to a data warehouse according to business needs Once your use case is live, you need to look at cross-cutting concerns like cost management, update management, troubleshooting, security, access-control, ... We all know, the devil is in the details. Building a self-service infrastructure, making sure your developers don't spend all their time juggling between 10 different heterogeneous systems to work on their data product is not as easy as it sounds. It will take at least a few months and dozen of iterations to get it right. Operating, maintaining and extending your data platform comes at a significant cost Creating a full-fledge data platform takes a huge amount of time Once the infrastructure has landed, it's even harder to keep your projects live Conveyor is meant to be a centralized home for all your data projects, while preserving the freedom of each engineer or team to use their favorite tools or frameworks. You can get a head start on your data use-cases right using templates favoring software engineering best-practices. Use scaffolding and templates for projects as well as abstract away infrastructure Decrease time to market by streamlining application lifecycle Use monitoring and evergreen strategies to keep costs under control Consulting Conveyor Product & Features Comparison Docs Academy Our offering Resources Cases Blog About us Team Join us Cloud Partnerships Pricing Vismarkt 17, 3000 Leuven, Belgium info@dataminded.be Vat. BE.0667.976.246 Consulting Conveyor Academy Resources About us More Conveyor offers plans adapted to each type of user. ​ Plans range from Free, enabling you to start quickly, all the way to Enterprise, allowing you to meet strict compliance regulations.  Features ​ CLI​ ​ WEB UI ​ Templates   ​   users ​ projects ​ environments ​ clusters ​ core hours ​ ​ ​ Spot nodes ​ Batch jobs ​ Streaming jobs ​ Notebooks ​ ​ ​ Cost dashboard   RBAC ​ SSO ​ Roles ​ ​ ​ Productivity audit   cost audit ​ feature development ​ ​ ​ SLA   Support ​ Cloud ​ Free ​ ​ ​ ​ ​ ​ ​ ​   Unlimited ​ Unlimited ​ 1 ​ 1 ​ 5000 ​ ​ ​ ​ ​ ​ ​ ​ ​ ​ ​ ​ ​  ​  ​  ​ 1 ​ ​ ​  ​  ​  ​ ​ ​ Best effort   Community ​ AWS Cloud ​ Team ​ ​ ​ ​ ​ ​ ​ ​ Unlimited ​ Unlimited ​ Unlimited ​ 1 ​ Unlimited ​   ​ ​ ​ ​ ​ ​ ​  ​ ​ ​  ​  ​  ​ Multiple ​ ​ ​  ​  ​  ​ ​ ​ 99% ​ Standard 
AWS and Azure ​ Enterprise ​ ​ ​ ​ ​ ​ ​   ​ Unlimited ​ Unlimited ​ Unlimited ​ Unlimited ​ Unlimited ​ ​ ​ ​ ​ ​ ​ ​ ​  ​ ​ ​ ​ ​ ​ ​ ​ ​ Multiple ​ ​ ​ Quarterly ​ Quarterly ​ Prioritized  ​ ​ ​ SLA Tailored   Premium ​ Any cloud ​ The pricing is for the Conveyor platform only. It does not include pricing for any required cloud resources (e.g. compute instances, databases, ...). The baseline cloud cost for a single cluster is about 10 USD per day or about 300 USD per month. Unlimited users, projects Single cluster and environment 5000 core hours to play and try Single RBAC role AWS only Community support Everything on the free plan and Unlimited environments Unlimited core hours Cost dashboard 99% SLA uptime AWS and Azure Standard support Everything on the team plan and Unlimited clusters SSO support Multiple RBAC roles Productivity and cost auditing Custom SLA uptime Prioritized feature requests Premium support Any cloud Use the following steps to estimate the Conveyor and instance costs for a particular workload.  ​ Let’s say you have two environments (staging and production). Each environment runs 10 DAGs with each one an average of 20 tasks. We will calculate the monthly costs for only the production environment were the jobs run daily. ​ In our example, the 20 tasks are split into 2 types: 10 Spark jobs running one mx.small driver and five mx.medium executors for 30 min. 10 container jobs running one mx.medium instance for 10 min. ​ Conveyor proposes multiple job compute types. In order to simplify calculations, we convert any types's number of hours of compute back to equivalent mx.medium hours. By definition, this type has 1 cpu core and 4 GiB mem. ​ The mx.small has 0.5 cpu cores, so this means that 1 hour of this instance is equivalent to 0.5 hours of an mx.medium.   Let’s do it for the production environment. ​ Spark hours Spark executor: 10 DAGs * 10 tasks * 5 executors * 1/2hour* 30days = 7500 mx.medium hours Spark driver: 10 * 10 * 1/2 hours *30 = 1500 mx.small hours = 750 mx.medium hours. ​ Container hours Container jobs: 10 * 10 * 1/2 hours *30 = 1500 mx.medium hours ​ Total hours Monthly you will use 9750 mx.medium hours. ​ The Conveyor license costs are computed in core-hours. Because the mx.medium has a single cpu core, you can reuse the total amount of mx.medium hours without any additional multiplication. ​ For the production environment this means that 9750 instance hours will cost you 487.5 EUR in licensing cost for one month using the Conveyor Team plan. ​ An mx.medium job is a Conveyor concept. The underlying Kubernetes cluster itself can run on many types of instances. Kubernetes will scale the number of actual worker nodes for you based on the required number of cpu cores and memory. This means that for an estimation, you will need to roughly convert the mx.medium (1 cpu, 4 GiB mem) to the actually provisioned cloud instance.   Let’s say on AWS a mx.medium job is running on a m6i.mxlarge (4 cpu, 16 GiB mem) instance with an hourly cost of 0.214 EUR. A single mx.medium job hour is then roughly equivalent to 0.25 of a m6i.mxlarge hour, thus costing 0.0535 EUR per hour. ​ For our production environment, this means that the 9750 instance hours results in a cost of 521.63 EUR when running on-demand. ​ If you would run on spot instances, we can reduce this cost up to 90%, but let’s take a more conservative 70% reduction: 156.48 EUR. ​ This principle is the same on any cloud provider. The total conveyor cost is the sum of the license and the cloud cost. ​ Our monthly total cost for the production environment would be 1009.13 EUR when running on-demand, and 643.98 EUR when running on spot instances. Consulting Conveyor Product & Features Comparison Docs Academy Our offering Resources Cases Blog About us Team Join us Cloud Partnerships Pricing Vismarkt 17, 3000 Leuven, Belgium info@dataminded.be Vat. BE.0667.976.246 Consulting Conveyor Academy Resources About us More Consulting Conveyor Product & Features Comparison Docs Academy Our offering Resources Cases Blog About us Team Join us Cloud Partnerships Pricing Vismarkt 17, 3000 Leuven, Belgium info@dataminded.be Vat. BE.0667.976.246 Consulting Conveyor Academy Resources About us More When you want to transform data into value, you have 2 options: either you outsource this process to experts, or you attempt to do it yourself. Since technology is ever evolving at enormous speeds, the latter might be hard since you might not have the know-how internally.   At Data Minded, we help you with the value extraction process in both ways: you can use our consultancy services, or improve with our academy services. With the academy, our shared intent is to make you more capable in record time. We offer workshops on key technologies and data challenges that are common in even the best data driven companies. We not only organise workshops for our clients but also teach at different business schools. Some of our thoughts and findings are captured and accessible through our Youtube channel. In addition, we organise yearly Winter and Summer schools, lasting one week, in which we dive deep into several key technologies. In short, there’s something for everyone! Have a look at our catalog of ready-to-go courses. Tag along in one of our workshops scheduled at predetermined dates. By subscribing you will be able to participate in a 1 to 3 day workshop , depending on the topic, where our experienced instructors will not only help you to grasp the essentials but also teach you the best practices of fundamental technologies, key concepts and modern techniques related to data and engineering. Twice a year we organise a week full of interactive workshops led by our experienced instructors. The content is a carefully selected subset of our standard courses, reduced in length to fit within one week. As cherry on the cake, we end the week with a capstone exercise in which participants get to combine all they’ve learnt in that week in one coherent package, combining several cloud services and technologies, illustrating many concepts of a modern data platform. Don’t want to wait for the courses and workshops that we offer at predetermined dates? Or are you in need of a tailored workshop that fits your business? No problem! Reach out to us to discuss a custom training program for your business. Remote or on-premises, we have experience with both approaches, and even run hybrid formats: with flipped-classroom trainings, participants watch the theory upfront, and then join the interactive sessions to have the material deeply ingrained. Classroom trainings Remote sessions On premise Consulting Conveyor Product & Features Comparison Docs Academy Our offering Resources Cases Blog About us Team Join us Cloud Partnerships Pricing Vismarkt 17, 3000 Leuven, Belgium info@dataminded.be Vat. BE.0667.976.246 Consulting Conveyor Academy Resources About us More The manifesto is a set of principles that will make sure your projects will be delivered on time, empower your people, and ensure the stability of your products. ​​ This is based on our collective experience from all of our projects. A data engineer creates software by writing code while following best practices. This includes adopting software design principles, version control, automated testing, CI/CD, Cloud-Native, and DevSecOps practices.  ​Without customers that actually use it or buy it, data is not generating anything. It is a product and we should treat it like one and measure how successful it is: usage, time-to-market, quality, availability, ...  As data engineers, we build custom data pipelines for complex use cases. For more common use cases we provide self-service solutions. We are an enabler in an organisation.  Public cloud providers have drastically changed the playing field of data engineering over the last few years. They have increased flexibility while lowering the operational burden. There are still valid exception scenarios but cloud is the new default.  While it might be more interesting to build a real-time data stream, it can add unneeded complexity (state, replay, ... ). If your use case only requires data once per day, keep it simple, keep it stupid, keep it sustainable! This doesn’t mean we shy away from stream processing when needed. ​Consistency is a powerful weapon yet there is no golden hammer. For each use case, we try existing “boring” technologies first, rather than selecting a technology to expand our own knowledge and experience. We will use bleeding edge technology when we have good reason to do so. Notebooks bring value at the beginning of a data product when exploring data,  looking for potential solutions and documenting along the way. The structure of notebooks does not incentivize good software design patterns though. So once you are done exploring, a proper IDE is the right tool for the job.  Data engineers and data scientists share a common technology stack, yet they often play a different role in the organization. This can lead to a dysfunctional marriage but it doesn’t have to. We work together and see the best results emerge in cross-functional teams.  Over the years we have seen the rise of domain-specific languages and drag-and-drop tools. Nothing has come close to the expressiveness and adoption of SQL. We see it as the bridge to enable less technical profiles and we favor it as the interface in self-service solutions.  ​ Check out the webinar to have more in-depth ideas about the  Data Minded Manifesto. Consulting Conveyor Product & Features Comparison Docs Academy Our offering Resources Cases Blog About us Team Join us Cloud Partnerships Pricing Vismarkt 17, 3000 Leuven, Belgium info@dataminded.be Vat. BE.0667.976.246 Consulting Conveyor Academy Resources About us More Data maturity demonstrates the level at which a company makes the most out of its data. The more data mature a company is, the more data efforts become interconnected with different aspects of the organisation. 
Whether you're aiming for innovative AI/ML products or are more focused on data analytics, you'll need the right data engineering efforts to create an underlying future-proof data platform.   Determine whether you are on the right track using the tool below, so you can take action right away! Our Data Maturity Scan will quickly give you an idea how good your company scores. ​ Answer 6 questions by selecting which practices currently apply within your company. 
  Get insights into how data mature your organisation is and on which categories your company scores well.
  ​Compare your score with industry benchmarks.
  Get started on improving your data maturity by following the tips from our whitepaper. Consulting Conveyor Product & Features Comparison Docs Academy Our offering Resources Cases Blog About us Team Join us Cloud Partnerships Pricing Vismarkt 17, 3000 Leuven, Belgium info@dataminded.be Vat. BE.0667.976.246 Consulting Conveyor Academy Resources About us More Introducing cloud for doing ML training at scale Industrialising ML use cases with a central Data & Analytics platform (“NEO”) and long-lived business teams. Datafy is at the heart of NEO.  Scaling advanced analytics to continuously improve customer experience of media products Implementing more accurate sales forecasting to drive more efficient operations Setting up a SaaS product on AWS. Leveraging cloud scalability to meet client demand. Consulting Conveyor Product & Features Comparison Docs Academy Our offering Resources Cases Blog About us Team Join us Cloud Partnerships Pricing Vismarkt 17, 3000 Leuven, Belgium info@dataminded.be Vat. BE.0667.976.246 Consulting Conveyor Academy Resources About us More Conveyor is Data Minded's managed, cloud-based data platform for building and running secure and reliable data products. Unlike many other platforms, Conveyor focuses on removing the infrastructure and process barriers that are typically encountered in the lifecycle of a data project.  During this webinar, we introduce Conveyor and talk about why we built it. We will also dive into a concrete data product usecase and go through the various lifecycle stages of the data product development using Conveyor, and highlight how it helps you along the way.  Understanding the ambitions and the current data maturity level is crucial before starting or continuing your data journey. Therefore Data Minded developed a Data Maturity Index that helps you visualize the balance in your data organization. Not only is the Data Maturity Index helpful to focus on the actual bottlenecks and set priorities, it also is a benchmark to visualize the impact of engagements and transformations. During this webinar you will learn: → What data maturity is and how we came to the Data Maturity Index → Why you should (or should not) grow your data maturity → Who the people behind the Data Maturity Index are   Test your data maturity Many data projects begin and end with experimental code running in a notebook. But when you have to support the code in production, you often hit the limitations of notebooks. These limitations are hard to maintain, hard to debug, hard to reuse and hard to extend.   So you need to look for ways to package and deploy your code in a more consistent, reliable way. And this is exactly why containers have taken the software engineering world by storm and why the data world is seeing a rapid adoption of container technology. In this webinar we will take you, step by step, through the process of converting a classical python or spark notebook into a reliable, scalable and portable container that can run on any cloud or even on your laptop. We will use open-source templates to help you get started and clarify some of the magic that goes on behind the scenes. Do you want to be kept informed about our upcoming webinars?  Fill out your email address and we will send you invites for our upcoming webinars.  Consulting Conveyor Product & Features Comparison Docs Academy Our offering Resources Cases Blog About us Team Join us Cloud Partnerships Pricing Vismarkt 17, 3000 Leuven, Belgium info@dataminded.be Vat. BE.0667.976.246 Consulting Conveyor Academy Resources About us More Partner - CEO Engagement Manager Datafy Lead  Data Engineer Data Engineer Data Engineer Data Engineer Data Engineer  Marketing Manager Partner - CTO Engagement Manager Office Manager Data Engineer Data Engineer Data Engineer Data Engineer Data Engineer Data Engineer Partner - COO Head of Data Minded Academy Office Manager Data Engineer Data Engineer Data Engineer Data Engineer Data Engineer Consulting Conveyor Product & Features Comparison Docs Academy Our offering Resources Cases Blog About us Team Join us Cloud Partnerships Pricing Vismarkt 17, 3000 Leuven, Belgium info@dataminded.be Vat. BE.0667.976.246 Consulting Conveyor Academy Resources About us More Excited about Data Minded and what the team accomplishes together with clients? Ready to use your skills, passion and drive to strengthen our team of data engineering specialists? Check out our career opportunities and give us a shout. At Data Minded, data engineers are at the heart of what we do. As part of our young and fast-growing team based in Belgium, you take part in complex data analytics projects through their entire lifecycle.  Consulting Conveyor Product & Features Comparison Docs Academy Our offering Resources Cases Blog About us Team Join us Cloud Partnerships Pricing Vismarkt 17, 3000 Leuven, Belgium info@dataminded.be Vat. BE.0667.976.246 Consulting Conveyor Academy Resources About us More At Data Minded, we strongly believe in Cloud. Cloud allows organizations to scale quickly and elastically, and focus on their core business. Our data engineers are highly knowledgeable about the different services offered by the major cloud providers, and can help your organization to leverage their capabilities to the fullest.  We are proud partners of the main three public cloud providers: Amazon Web Services (AWS), Microsoft Azure, and Google Cloud Platform (GCP). Our partnerships allow us to stay ahead of the curve, and serve our clients with bespoke solutions that fit their needs.  With more than 20 AWS certificates, including various specializations such as security, data analytics, machine learning,… and over 20+ projects successfully built and deployed on the Amazon cloud, it's safe to say we know the ins and outs of what AWS has to offer. From containers on EKS, to streaming with Kinesis, to AI/ML with SageMaker: together with our clients, we can build state-of-the-art data platforms and products. 
Check out our AWS partnership page, and get a taste of what we can do for you via our AWS customer success stories. Scheduling pipelines with Azure Data Factory, training machine learning models on Azure ML, managing identities and access rights at enterprise scale with Azure AD,… several of our clients rely on these core services of Microsoft's cloud. Whether you are just at the start of your cloud journey, or an already experienced cloud organization, Data Minded can help you with your Azure endeavors at scale. ​ You can find us in the Azure Partner directory. Google Cloud Platform is home to some of the most loved cloud services out there. Whether you want to extract insights from large amounts of data with BigQuery, build a truly serverless streaming application with PubSub, or harness Kubernetes' flexibility without its complexity with GKE, GCP has got you covered. We, at Data Minded, enjoy coming up with creative solutions that leverage these services in order to help our clients succeed. ​ You can find us listed as an official partner on our GCP Partnership page. Consulting Conveyor Product & Features Comparison Docs Academy Our offering Resources Cases Blog About us Team Join us Cloud Partnerships Pricing Vismarkt 17, 3000 Leuven, Belgium info@dataminded.be Vat. BE.0667.976.246 Consulting Conveyor Academy Resources About us More At Data Minded, data engineers are at the heart of what we do. As part of our young and fast-growing team based in Belgium, you take part in complex data analytics projects through their entire lifecycle. Besides design and implementation, this also includes following up on project schedules, identifying risks and clearly communicating them to project stakeholders. ​ You're interested in helping organisations become data minded and your idea of fun involves scalable compute clusters or massive data processing. You are convinced sensor data and IoT will have a big impact on society in the coming years and you want to be part of that shift. You are a fan of open source technology and you are not blind to its pitfalls. You are eager to learn and you like to work in a dynamic, no-nonsense start-up environment. Data Minded is a fast-growing team, passionate about data. We are all engineers. We all write code on a daily basis. We put our people ahead of our products and our products ahead of our profits. We choose long-term gains over short-term profits. We are big believers of open source, cloud technology and IoT. We are based in Leuven. ​​ Data Minded has grown from an idea to becoming a local leader in data analytics. We have delivered several successful projects in the areas of telecom, healthcare, biotech and others. We provide technical training to the community and advise large corporations on how to approach data projects. To achieve these results, we keep an open mind, we adapt fast and we always tell the truth as we see it. We coach and mentor each other. We learn from our mistakes and share our learnings. Architect, develop and deploy a wide range of data applications, both on-premise and in the cloud ​ Design complex analytics solutions with large data sets on distributed systems ​ Work independently, prioritize multiple stakeholders and tasks, and manage work time effectively. ​ Provide thought leadership for clients and partners to help them understand the data analytics landscape Bachelor in Computer Science or related technical field, or equivalent practical experience. ​ Programming experience with one or more languages: Python, C#, Java, Scala, C/C++, ... ​ Basic understanding of databases and SQL ​ Linux experience ​ Highly proficient in spoken and written English MS/PhD degree in Computer Science, Math or a technically oriented field. ​ 5 years of relevant experience in software development, solution engineering, technical consulting; with expertise in architecting and rolling out new technology and solution initiatives. ​ Experience with big data technologies (such as Hadoop, Spark, Cassandra, Elasticsearch) ​ Excellent coding skills and deep knowledge of SQL ​ Knowledge of data science and machine learning algorithms, on large data sets. ​ Good understanding of cloud possibilities and limitations in the areas of distributed systems, load balancing and networking, massive data storage, and security. ​ Able to mentor junior members and give technical advice and direction. ​ Knowledge of Dutch and/or French Then we would love to talk with you! Get in touch by sending an email to 
careers@dataminded.be Consulting Conveyor Product & Features Comparison Docs Academy Our offering Resources Cases Blog About us Team Join us Cloud Partnerships Pricing Vismarkt 17, 3000 Leuven, Belgium info@dataminded.be Vat. BE.0667.976.246 Consulting Conveyor Academy Resources About us More Introducing cloud for doing ML training at scale BICS is a communications platform company providing international communications, messaging and connectivity to operators and enterprises, globally. BICS relies heavily on ML predictive analytics in several use-cases: to forecast pricing evolution, combat fraud, analyse mobility, etc. Most of the data processing and analytics is happening in a local data center, BICS wants to experiment with a hybrid setup, where some ML jobs run in the cloud. The main benefits of the cloud in this context is scalability and cost efficiency. execute one ML use-case in the cloud, fully integrated into the existing data processing framework Adapt the existing software tooling (CI/CD, scheduler, network connectivity) to work with cloud resources. We set up a machine learning environment on AWS, leveraging SageMaker. Model predictions, model training and also hyperparameter tuning jobs are all running on SageMaker. The SageMaker jobs are integrated with the on-premises scheduler, and data flows seamlessly between on-premises network and the cloud. Scalability of the cloud means that BICS can run on-demand ML tuning jobs, while keeping their existing on-premises cluster for scheduled jobs This drives more innovation and experimentation, resulting in a more scalable and sustainable way-of-working for their data scientists Consulting Conveyor Product & Features Comparison Docs Academy Our offering Resources Cases Blog About us Team Join us Cloud Partnerships Pricing Vismarkt 17, 3000 Leuven, Belgium info@dataminded.be Vat. BE.0667.976.246 Consulting Conveyor Academy Resources About us More Introducing cloud for doing ML training at scale Industrialising ML use cases with a central Data & Analytics platform (“NEO”) and long-lived business teams. Datafy is at the heart of NEO.  Scaling advanced analytics to continuously improve customer experience of media products Implementing more accurate sales forecasting to drive more efficient operations Setting up a SaaS product on AWS. Leveraging cloud scalability to meet client demand. Consulting Conveyor Product & Features Comparison Docs Academy Our offering Resources Cases Blog About us Team Join us Cloud Partnerships Pricing Vismarkt 17, 3000 Leuven, Belgium info@dataminded.be Vat. BE.0667.976.246 Consulting Conveyor Academy Resources About us More Industrialising ML use cases with a central Data & Analytics platform (“NEO”) and long-lived business teams. Datafy is at the heart of NEO.  Luminus is the second largest electricity producer and energy supplier on the Belgian energy market. In 2019, Luminus successfully started experimenting with machine learning, but had no experience with operating machine learning use cases. The Luminus’ technology stack was built for traditional business intelligence, on on-premise infrastructure. Set-up an operating model and cloud-native data & analytics platform which allows to build and run machine learning applications, leveraging on self-service. Implementation of a new IT-oriented Landing Zone and Data & Analytics Platform capabilities​, based on Data Minded Cloud. It covers the full machine learning workflow from experimentation to monitoring, and required design patterns (batch processing; streaming). We have set up long-lived business-oriented use cases teams, including new roles across business lines and IT. This new way of working helped to establish a culture of increased ownership, innovation and learning. Within one year, 25+ users (scientists and engineers) were on-boarded, 7 use cases went live; 18 projects have started; 21 data sources were connected. Positive ROI after delivery of first use cases. Widespread adoption of data platform in different business lines. Continued value-driven industrialisation of new use cases. Strong cultivation through Data Minded Academy. Consulting Conveyor Product & Features Comparison Docs Academy Our offering Resources Cases Blog About us Team Join us Cloud Partnerships Pricing Vismarkt 17, 3000 Leuven, Belgium info@dataminded.be Vat. BE.0667.976.246 Consulting Conveyor Academy Resources About us More Scaling advanced analytics to continuously improve customer experience of media products DPG Media is a leading media group with activities in Belgium, the Netherlands and Denmark. DPG Media owns several popular brands in newspapers & magazines (Het Laatste Nieuws, De Morgen, Humo), radio & television (QMusic, VTM) and online services. DPG Media has the ambition to become the local leader in the media landscape and therefore decided years ago to make the full switch to cloud, to invest in mobile and digital products with HLN Mobile and VTM GO, the Flemish Netflix as an example. Advanced analytics powered by artificial intelligence and machine learning are an instrumental tool for DPG to continuously improve customer experience of its media products. Since early 2017, Data Minded has been a trusted partner of the data lake team, enabling the entire organisation to create self-service use cases for data analytics and successfully rolled out Datafy as a managed data engineering platform The team is responsible for maintaining the central data platform, from infrastructure and workflow management to delivering data products, data science workbenches and reporting tools to the rest of the organization. In addition, they are also responsible for ingesting and processing major batch and streaming data sources such as CRM, clickstream, advertising, sales and marketing data. Data Minded also provides training and advice on data architecture. The platform technology stack mainly consists of open-source software components such as Scala, Python, Airflow, EKS Kubernetes, CodeBuild/CodePipeline, Terraform, Gradle, Kafka, Elasticsearch, and many more, all built on AWS cloud. Within one year, 600+ users (scientists and engineers) were on-boarded,  50+ use cases went live; 2800 projects have started; 60+ data sources were connected. This degree of adoption was only possible by rethinking the way of working: Harmonising processes and tools across Belgium and the Netherlands, Cloud migration, Managed cloud-native data engineering platform, A central data repository for all teams for data discovery, data governance and data sharing. DPG Media & Data Minded succeeded in creating a complete 360° view of its customers by combining both online and offline data to provide personalised recommendations for their media products. In addition, rethinking the way of working improved operational efficiency, reduced legacy and thus improved costs. Consulting Conveyor Product & Features Comparison Docs Academy Our offering Resources Cases Blog About us Team Join us Cloud Partnerships Pricing Vismarkt 17, 3000 Leuven, Belgium info@dataminded.be Vat. BE.0667.976.246 Consulting Conveyor Academy Resources About us More Implementing more accurate sales forecasting to drive more efficient operations Newpharma is market leader in Belgium and France in online pharmacy and plays a prominent role on the European market. The company reached out to Data Minded to help kick off its analytics transformation. The project started off with the case of predicting future sales. In the past, Newpharma steered the planning of its logistics operations workforce using basic sales forecasting models enriched with market and process experience. As the number of its customers and products increased dramatically, Newpharma decided to look for a more data-driven and scalable approach to forecast sales and organize its operations. In a first two-week period, we have explored a wealth of data (historical sales, product catalogue, marketing campaigns, weather, etc.) as well as different predictive modelling techniques. Subsequently, we were able to outperform the legacy model using the acquired information and insights. ​ After this positive result, Data Minded has designed and implemented a data platform based on AWS Cloud, Airflow, Spark and Python to train and run an LSTM model on a daily basis and publish order predictions. Kubernetes is used as an orchestration solution for automating and scaling infrastructure and applications. On average, the new predictive model engineered by Data Minded is 33% more often within the ±10% error range compared to the existing legacy approach. In addition, the end-to-end data processing and analytics is now fully automated. The Data Minded specialists succeeded in completing the entire project within a period of two months. The stream of consistently more accurate sales predictions enables Newpharma to streamline its operations accordingly. Considering the large scale of Newpharma's operations, this involves expenditure savings that are huge. The scalable and structured approach of Data Minded intrinsically leads to a more efficient and targeted use of human resources. Consulting Conveyor Product & Features Comparison Docs Academy Our offering Resources Cases Blog About us Team Join us Cloud Partnerships Pricing Vismarkt 17, 3000 Leuven, Belgium info@dataminded.be Vat. BE.0667.976.246 Consulting Conveyor Academy Resources About us More Setting up a SaaS product on AWS. Leveraging cloud scalability to meet client demand. Kwarts is a start-up in the area of life science and medical affairs. Their SaaS product, A-Inside, helps pharmacological companies with their customer relationship: offering the most relevant product at the appropriate time via the best communication channels. Setting up a cloud-based architecture for data analytics Setting up the data processing pipelines at one client Setting up the environment for the in-house developed state of the art machine learning models Setting up the SaaS user interface at one client Enabling efficient scaling to m clients in short term The supporting AWS infrastructure was set up and configured Data ingestion pipelines were developed and deployed at one client Integrating the SaaS product: data ingestion, ML predictions and displaying the results Pilot of the SaaS product is running at 1 client Demos of the product at multiple clients Consulting Conveyor Product & Features Comparison Docs Academy Our offering Resources Cases Blog About us Team Join us Cloud Partnerships Pricing Vismarkt 17, 3000 Leuven, Belgium info@dataminded.be Vat. BE.0667.976.246 Consulting Conveyor Academy Resources About us More Databricks is one of the most popular tools for building and running SQL, python and R notebooks. It provides a great way to get started and experiment with your first data pipelines. Conveyor focuses primarily on delivering high quality data products which is not possible through only a notebook environment. Notebooks are great for experimenting and creating a first version of your code due to it's interactive environment but they have several drawbacks for writing production code: No modular code
Difficult to share code as well as as navigate across multiple notebooks in the Databricks UI
  No tests
No easy way to write tests and thus protect against regression
  Not reproducible
Dependent versions of python, Spark are not specified in the notebook but in the Databricks cluster
  No configuration parameters/files
Managing configuration is difficult, Databricks only provides the dbutils package but this is not portable outside Support both notebooks and IDE
Use notebooks for experimentation but your IDE to write modular and easy to maintain code
  Add tests to your code
  Docker image
Code is packaged with all dependencies to make it truly build once, deploy anywhere
  Airflow dags
Airflow configuration can use environment variables, extra arguments to customize your code Databricks has poor support for creating data pipelines: Managing tens or a hundred of data projects with Databricks is both challenging as well as costly:​ Data access on a workspace
All notebooks in the same workspace can access the same data. To separate them by using different workspaces
  Databricks clusters per team
In order to make teams independent, they need their own cluster as it defines the python, spark,... versions 
  Databricks licence fee of 50-80%
On top of the raw compute cost of your cloud provider
  Use latest source code in job
A job in Databricks runs the latest version of your notebook, which is not necessarily the latest committed code
  Job dependencies
Limited support to express depencencies between notebooks
  Notebook dependencies
Many library, framework versions are defined on cluster level instead of in your notebook 
  No overview on all jobs
Difficult to monitor all jobs of a given day Docker image
All code and depencencies are packaged in a docker image such that you know exactly which version is being executed by your job.
  Airflow
Airflow has extensive support for defining complex Dags as well as a UI with an overview of jobs
  Notebook dependencies
Many library, framework versions are defined on cluster level instead of in your notebook  Data access per project
We support the principle of least privilege by linking data access to project/job
  RBAC (role-based access control)
is used to define permissions for users on projects/environments
  Cost dashboards
Give insights into costs in order to reduce them  Databricks added support for Repositories which is a big improvement to manage multiple notebooks. There are however still 2 major issues when collaborating with multiple people: git is not a first class citizen
You can not make changes to the same file with multiple people at the same time 
  Cannot develop notebooks from your IDE
When working with multiple people, you need a premium cluster which does not support connecting to it from your IDE Native GIT integration
Create feature branches and merge changes when working with multiple people on the same files Consulting Conveyor Product & Features Comparison Docs Academy Our offering Resources Cases Blog About us Team Join us Cloud Partnerships Pricing Vismarkt 17, 3000 Leuven, Belgium info@dataminded.be Vat. BE.0667.976.246 Consulting Conveyor Academy Resources About us More EMR is the default way to run Spark Jobs on AWS. It's a stable environment with a genuinely fast runtime. The main differences with Conveyor are: ​ Know and configure AWS infrastructure details
Manually configure VPC's, IAM roles etc
  No 1 way to use notebooks
EMR studio, EMR notebooks, Sagemaker are candidates
  Configure a tool to manage workloads
Use managed workflows for AIrflow, Step functions or a homebrew solution
  Conveyor environments with managed Airflow
Schedule containers or spark jobs on the cluster
  Notebooks for experimentation
Explore data or test ML algorithms with one command
  Conveyor run command
Start Spark or container jobs on the cluster from your local environment In EMR, you have to create and manage a cluster to schedule your jobs.​ IAM roles are linked to a cluster
Use 1 cluster per job if you want to use different IAM roles
  Clusters do not autoscale by default
  Clusters do not update automatically
  Clusters are bound to spark/hadoop versions
When sharing a cluster, all applications need to be updated at the same time
  Creating a cluster takes up to 15 minutes
  EMR on EKS
Manage the EKS data-plane with all components yourself Conveyor manages clusters for you
  One cluster for all jobs
Each job can use a separate IAM role
  We run containers
Run the same container locally or anywhere else
  Mix spark/hadoop versions on one cluster
All dependencies are packaged in docker containers Any job type existing in the Hadoop ecosystem
Spark, Pig, Hive, etc are supported
  (Too) many ways to package code
Jars, pyfiles, pex distributions, containers,...
  No support for non Hadoop jobs
Cannot run simple python code Any container can be run non-distributed
Use your favorite programming language
  Use spark for distributed jobs
For processing large volumes of data
  DBT for data warehouse transformations
lower the barrier for data analysts to use and process data Consulting Conveyor Product & Features Comparison Docs Academy Our offering Resources Cases Blog About us Team Join us Cloud Partnerships Pricing Vismarkt 17, 3000 Leuven, Belgium info@dataminded.be Vat. BE.0667.976.246 Consulting Conveyor Academy Resources About us More From destination unknown to a guided data journey A solid data strategy, architecture and infrastructure allow organizations to focus efforts on where it matters most i.e. value creation. What makes your organization stand out to competition? What is your customer paying for? Where can you improve the customer journey with innovative services or democratize your product and services? If it is not adding value to your customer, ask yourself if it is really needed or if another party can do it better. Continuously making these reflections helps you to grow your core business.    Data Minded helps to drill down to your core business value and create an achievable plan for the future. It always starts with a profound understanding of the corporate & digital ambition, and how data & analytics enable this ambition. Based on the ambition and current data maturity level every organization has different needs and has to set different priorities. Practice shows that it is not always easy to look at the bigger picture when you need to keep the lights on, pressure is put on teams to continuously deliver new use cases and budgets are challenged. As a result companies often use a certain technology or process until it is end-of-life and are confronted with complex transformation programs.    If you recognize one of the following pain points, the time might be right to start a data strategy exercise or reassess your current architecture: ​ Misalignment between IT, data & analytics and business High dependency on legacy systems and  Difficulties to attract skilled data & analytics profiles Data products that don’t get industrialized Drift of ML model performance is not monitored ​ Start the journey with our experienced guides At Data Minded, we support our clients in achieving their data ambitions. Data Minded offers data strategy, data architecture and cloud infrastructure services to help organizations get the most value possible from their data.     Working with Data Minded allows you to leverage industry best practices and take a head start. Together we ensure there is a solid foundation to create long term business value. This foundation is best represented by the AI hierarchy of needs. ​ Our end to end knowledge has proven to be an important asset to guide clients to the top. Data Minded has a structured methodology to translate the corporate and digital strategy towards your data organization. We start from the value question and work towards an achievable roadmap. We go further than your techstack definition and creates a holistic view on your current and desired data & technology capabilities and operating model. We look at following dimensions: Last but not least we also aim to build engagement on all levels of the organization during our data strategy exercise. Data Minded does this by organizing thought leadership and best practices workshops transversely across dimensions & phases. In these workshops we inform and inspire you on topics such as data mesh, cloud architecture, BI best practices, streaming, machine learning, self service,... .   We believe that applying this methodology in an inclusive way in your organization, helps you build the required engagement to build and run a sustainable and scalable data organization. Whereas a data strategy helps you translate the corporate and digital strategy towards your data organization, the data architecture study has as an objective to clarify the how of your data strategy.   Together with the IT and data & analytics teams we define the technical landscape and operating model and have a detailed look into all dimensions: We address topics such as how to go cloud native, how to deal with security, which concepts are needed for implementation (a data warehouse, an event streaming system, …), how to do logging and monitoring, what is the ideal organization and corresponding roles & responsibilities? Going from your current situation to the desired state implies that you also have to deal with different types of constraints e.g. budget, legacy systems, culture,... . Together we set priorities, create a business case and define a roadmap. Often also a Proof of Concept is performed to ensure feasibility of the data architecture. Organizations often decide to go to the cloud. Most prominent reasons mentioned by cloud service providers are: At Data Minded we strongly support organizations that move to the cloud for the above mentioned reasons. One would even think that the hardest part is over when the decision has been made to move to the cloud. However, experience has taught us that this is only the beginning of a complex journey. An organization that migrates to the cloud using mostly IaaS is doing a so-called 'lift-and-shift', or a copy-paste of their existing infrastructure. This gives you a lot of flexibility and control, and because basically every cloud provider has an IaaS offering, it is considered to be a commodity, and the markup of these services is quite low. However, you should not underestimate the time it will take you to actually set everything up and to manage the patching and updating of the OS and other software. In addition to IaaS, most service providers also take patching and software maintenance related work out of your hands with Platform-as-a-Service and Software-as-a-Service offerings.    Together with your technical team we plan the migration step by step whilst actively managing security, cost and time. Our experts provide you industry and technology best practices.  Consulting Conveyor Product & Features Comparison Docs Academy Our offering Resources Cases Blog About us Team Join us Cloud Partnerships Pricing Vismarkt 17, 3000 Leuven, Belgium info@dataminded.be Vat. BE.0667.976.246 Consulting Conveyor Academy Resources About us More Unlock the full potential of data The ultimate goal of every organization is to base strategies, tactics and decisions on insights that are not available to competition in order to create a competitive advantage. Achieving this is only possible when everybody and every system in an organization has access to the right data to create value added insights. Or in other words “data democratization”: ​ “Everybody has access to data and there are no gatekeepers that create a bottleneck at the gateway to the data. The goal is to have anybody use data at any time to make decisions with no barriers to access or understanding.” - Bernard Marr What if we tell you that this ultimate goal is achievable for everybody who puts the right effort in growing the data maturity. ​ Do you recognize these challenges on your way to data democratization? What pipelines and platforms need to be set-up to enable self service analytics Which dashboards and data visualization tools integrate best with the current tech stack What is the most optimal way to store & model my data: data warehouse vs data lake, data vaulting How should I set-up data governance, access & security Which training is required to improve data literacy of data & analytics teams and business   These are exactly the challenges we can tackle together so you can benefit from the advantages of data democratization: easily discover and access data, better and faster decision making and enforced security & compliance. Democratizing data within your organization requires action in 5 dimensions.  The objective of Data Minded is that our customers achieve their objective in a pragmatic and cost efficient way. Our clients can count on our expertise in every phase of their journey. 1. Self Service Analytics 2. Dashboards & Data Visualisation According to Gartner, Self-Service Analytics is a form of business intelligence (BI) in which line-of-business professionals are enabled and encouraged to perform queries and generate reports on their own, with nominal IT support.    Accomplishing this requires years of careful planning and a complete rethinking the enterprise data systems and architecture. Actually, it’s broader than merely a choice of tools. Processes, people and how you think about a product will need to adapt as well.    Data Minded can help you identify and visualize the areas that will help you reach a functional level of self-serviceness. We do this typically using our data maturity framework as a guideline. This can serve as a basis for your data strategy for the coming years. Creating value from data, necessitates converting raw data into data insights that are understandable and actionable to everyone. While other data management tools may make data more accessible, dashboards and data visualization tools (e.g. Tableau,  PowerBI, Data Studio) facilitate interpretation. ​ Data Minded helps to select the data platform that will feed the visualization tools. The number of vendors and platforms you could consider is huge. Based on what we saw at previous clients, Data Minded is in a unique position to form a neutral recommendation and accelerate the implementation and adoption. 3. Data Storage & Modelling Multiple options exist to structure your data to facilitate analytics i.e. a data warehouse, a data lake or a hybrid form called a data lakehouse. Each has their own pros and cons. https://www.fivetran.com/blog/what-is-a-data-lakehouse    There is not one version of the truth and organizational needs change when higher levels of data maturity are achieved. Often not only the data structure is changed but also the underlying infrastructure could be impacted when combined with a cloud migration. Much debate has been had about data modeling in the modern data space. Traditional  dimensional (star schema) modelling allows for fast and simple queries and is well suited for typical reporting needs. On the other hand, it isn’t all that flexible. Techniques like data vaulting add an additional layer of complexity which might sometimes be worthwhile.  4. Data Governance, Access & Security It is essential to make sure the data managed by your organization is protected and easy to access. Even more so when dealing with client data. Optimally managing enterprise data offers different advantages: ​ Access to high-quality data to improve the quality of analyses Secure and compliant with regard to regulation Consolidate data across multiple sources for increased efficiency Easily identify data dependencies and users of data sources
  Data Minded helps to make the right governance and security choices on every level of your tech stack. Data Minded doesn’t only ensure you have the right tools (e.g. Collibra, Datahub, Great Expectations, AWS IAM, etc.) and fit with your overall architecture, but also implement the right processes. Fundamentally, Data Minded believes in a decentralized data landscape following data mesh principles. Each team delivers its own set of data products which can be consumed by other teams in the organization. There is no one global data model for the entire organisation. Instead, each department models the data to their needs. New data products can be created to reuse those models. Eg: A customer360 view or a dimensional model of finance data. Data Minded has already implemented data warehouses and data lakes in multiple organizations. Before implementing changes, a deepdive is performed on the current challenges and needs. By looking at the bigger picture Data Minded guides organizations through the phases of design, development and implementation. 5. Data Literacy Having the tools, and processes is one thing. Adoption throughout the organization can only happen if people are proficient with them.    Different roles require different levels of knowledge and experience. Data Minded helps data engineers, data scientists, and data analysts learn the correct fundamentals and grasp more advanced concepts through our Data Minded Academy. Consulting Conveyor Product & Features Comparison Docs Academy Our offering Resources Cases Blog About us Team Join us Cloud Partnerships Pricing Vismarkt 17, 3000 Leuven, Belgium info@dataminded.be Vat. BE.0667.976.246 Consulting Conveyor Academy Resources About us More Scale your Artificial Intelligence projects from proofs-of-concept to production systems with MLOps MLOps is a set of practices that aims to deploy and maintain machine learning models in production reliably and efficiently. The word is a compound of “Machine Learning (ML)” and “DevOps”, a systemic approach of collaboration between software development and operational teams. The intrinsic goal of MLOps is to bring DevOps culture, processes, and tools right into the scope of machine learning practitioners.  A well-implemented practice of MLOps will enable your business to design, build and manage reproducible, testable, and evolvable ML-powered software. You should use it as a general tool to prioritize improvements in how your organization leverages AI & ML through its business. Adopting these principles will result in strategic edges like, among others, a decreased time to production for your use cases, and an increased product uptime for your deployed systems. 

MLOps is a concept that stimulates a lot of reflections these days. A few interesting works to refer to for further investigations could be the Google Cloud or Microsoft Azure resources about MLOps implementations. The MLOps reference website is also an interesting resource. Machine learning is hard. Building and maintaining systems embedding machine learning is even harder. Modern artificial intelligence requires way more than Data Science code to deliver value to your business. Provisioning a serving infrastructure, collecting and maintaining datasets, automating models training and deployments, monitoring the resulting predictions and insights… All these capabilities are unavoidable steps in your journey to machine learning at scale. On top of specific capabilities requirements, the rise of machine learning in modern IT stacks highlighted clear challenges for artificial intelligence developers. How to experiment with data in a quick and structured way keeping track of produced models and datasets? How to maintain symmetry between experimental and operational environments? In an ever-evolving world, how to keep our models relevant against new realities? Are you ready to start your MLOps journey? Good. In this journey, challenges are ahead and will be numerous but, at Data Minded, we will keep you covered. Implementing MLOps will challenge the way your organization and its whole IT stack are operating. Enabling data-driven use cases will require you to reconsider your organization's culture, people skillset, delivery methodologies, and general perception of data & AI. Sounds daunting, no? The good news is that building data platforms is our specialty at Data Minded. We already did it for clients from various industries and, there are good chances we are busy building new ones at the moment you will read these lines. Our experience put us in good position to help your organization making the transition from thinking about AI as a source of innovation to a critical source of business value. We can help you in all those tough decision-making processes involving people, platforms, implementations, and processes. You’d like to read concrete examples? Gotcha, follow along!   A machine learning project always starts from a good question that is instantiated from business challenges. Therefore, we will start together by defining what are the use cases that are worth living (and growing) in your AI portfolio. We will also aim to define what kind of business value you want to unlock and what are the key metrics associated. Our common goals are clearer? Perfect! Time to kickstart a project! On a day-to-day basis, we will help your teams to focus on iteratively answering your challenging business questions through researches and technical implementations.   Industrializing machine learning models is all about building a scalable and sustainable foundation. This requires bringing structure and standardizing your way of working. We will define, along with your engineering teams, how architecture components like CI/CD pipelines, model stores, feature stores, monitoring applications, or experimentation platforms will embed in your existing IT stacks. We will also help you building shareable organization-specific AI & ML template projects to speed-up the delivery of new use cases.   We don’t want your data platform and the DataOps/MLOps processes running there to become the Wild West of your IT department.  Count on us to help you framing the governance and lifecycle of the various projects built by your ML engineers. Down the road, you will only get more efficient, organized, and reliable!  Consulting Conveyor Product & Features Comparison Docs Academy Our offering Resources Cases Blog About us Team Join us Cloud Partnerships Pricing Vismarkt 17, 3000 Leuven, Belgium info@dataminded.be Vat. BE.0667.976.246 Consulting Conveyor Academy Resources About us More Looks like something went wrong.  Consulting Conveyor Product & Features Comparison Docs Academy Our offering Resources Cases Blog About us Team Join us Cloud Partnerships Pricing Vismarkt 17, 3000 Leuven, Belgium info@dataminded.be Vat. BE.0667.976.246
['https://www.dataminded.com', 'https://www.dataminded.com/consulting', 'https://www.dataminded.com/conveyor', 'https://www.dataminded.com/conveyor-product-and-features', 'https://www.dataminded.com/conveyor-vs-diy', 'https://www.dataminded.com/conveyor-pricing', 'https://www.dataminded.com/conveyor-contact', 'https://www.dataminded.com/academy', 'https://www.dataminded.com/data-engineering-manifesto', 'https://www.dataminded.com/dmi', 'https://www.dataminded.com/cases', 'https://www.dataminded.com/webinars', 'https://www.dataminded.com/team', 'https://www.dataminded.com/join-us', 'https://www.dataminded.com/cloud-partnerships', 'https://www.dataminded.com/data-engineers', 'https://www.dataminded.com/cases/bics', 'https://www.dataminded.com/cases/', 'https://www.dataminded.com/cases/luminus', 'https://www.dataminded.com/cases/dpg', 'https://www.dataminded.com/cases/newpharma', 'https://www.dataminded.com/cases/kwarts', 'https://www.dataminded.com/conveyor-vs-databrics', 'https://www.dataminded.com/conveyor-vs-emr', 'https://www.dataminded.com/data-foundations', 'https://www.dataminded.com/data-democratization', 'https://www.dataminded.com/mlops', 'https://www.dataminded.com/cases/luminus-neo']
comarison:  69550 67846
url list comparison 28 28
 Consulting Conveyor Academy Resources About us More Build sustainable and scalable data organisations that deliver on the promise of data and AI We are passionated about data engineering. We guide and deliver complex data projects through their entire lifecycle, from idea to production. 57 clients 138 data initiatives delivered 400+ people trained 200+ Conveyor projects Our consulting services include architecting and developing cloud-native data platforms, data pipelines and analytical applications.  Conveyor is a managed data engineering platform for building and running secure and reliable data products.  We help individuals and teams become better at data engineering. We co-create insights, skills and strong teams through online and offline training.  Understanding the ambitions and the current data maturity level is crucial before starting or continuing your data journey. Therefore Data Minded developed a Data Maturity Index that helps you visualize the balance in your data organization. Not only is the Data Maturity Index helpful to focus on the actual bottlenecks and set priorities, it also is a benchmark to visualize the impact of engagements and transformations. Offer new products and insights as a service and tap into new business opportunities. Increase productivity within your business and reduce lead times and costs. Stimulate exploration and scale for sustainable value creation. Facilitate cross-domain collaboration through data and reduce risk. Consulting Conveyor Product & Features Comparison Docs Academy Our offering Resources Cases Blog About us Team Join us Cloud Partnerships Pricing Vismarkt 17, 3000 Leuven, Belgium info@dataminded.be Vat. BE.0667.976.246 Consulting Conveyor Academy Resources About us More Data Minded Consulting covers a wide range of services that are developed to support our clients in every phase and area of their journey into data. Our services cross three wide areas Strategy Engineering Operations Get a taste for business value Scale to efficiently build new use cases Empower everyone to use data Consulting Conveyor Product & Features Comparison Docs Academy Our offering Resources Cases Blog About us Team Join us Cloud Partnerships Pricing Vismarkt 17, 3000 Leuven, Belgium info@dataminded.be Vat. BE.0667.976.246 Consulting Conveyor Academy Resources About us More Conveyor unites an entire ecosystem of modern tools and services into a single, simple workflow for building maintainable and cost effective data projects. Templates for various technologies and use case, get you started with just a couple of key strokes. Using the remote execution `run` command, you can execute your code remotely in the right context. Find out more about how Conveyor works Get started with a single command.
Scaffold your batch or stream processing project from one of our templates following industry best practices.
  Choose your compute size and deploy in seconds.
Use T-shirt sizing to select the appropriate size for the workload. Deploy to test and promote to production.
  Extend your use-cases with your own tools and libraries.
Containerization is at the core. Fit it in a container and run it. Easy journey from notebooks to production.
Embedded notebooks run in the same context as the project sharing code, environment and permissions. This enables using notebooks to debug and facilitates iterative industrialization of experiments. ​ Experiment and test in isolated environments.
Spin up new environments in seconds and avoid impacting your colleagues. Each environment comes with a dedicated workflow manager.
  Metrics and logs, out of the box.
Track performance and errors with live access to metrics and logs. Analyse cost per project.
With cost monitoring, you get insight into the most expensive data projects. Optimize where there is most to gain.
  Default to spot.
Using spot results in typical savings of 70-90% over on-demand pricing. Critical workloads can be configured to run on-demand, or mixed to get the best of both worlds.
  Fully managed.
Services and infrastructure are always up-to-date. No patching, no management, no worries. 37 projects - 53 users "Introducing new technologies and cloud adoption in data & analytics is a challenge, but getting IT and business on the same page can be an even bigger challenge. Working with Conveyor helps in managing the full ecosystem, it accelerates the scaling and it supports collaboration allowing data engineers and data scientists to focus on creating value with new data products, without having to worry too much about some of the underlying complexities of running a scalable data infrastructure in the cloud." Cristiana Pompei
IT Deputy Director Application Delivery at Luminus Run any workload that can be wrapped in a container at any scale. This standardizes the work across data engineers, data scientists and data analysts. Conveyor is adopted by organizations in various industries. Proud to be part of their data journeys and see them grow. Consulting Conveyor Product & Features Comparison Docs Academy Our offering Resources Cases Blog About us Team Join us Cloud Partnerships Pricing Vismarkt 17, 3000 Leuven, Belgium info@dataminded.be Vat. BE.0667.976.246 Consulting Conveyor Academy Resources About us More Cloud providers like AWS, Azure and GCP provide an overwhelming amount of great building blocks. When delivering data projects for our customers, we noticed the proposed stacks often:
  require a lot of glue code, resulting in workable yet sub-optimal user experiences aren’t actively encouraging software engineering practices require a steep learning curve to configure for your needs ​ In our opinion, one of the key dimensions for a better solution is high affinity with software engineering best-practices. Software engineering best-practices and automation leading to smooth deliveries are what make digital winners what they are today. ​ By using containers as the main medium to share softwares with the execution environments, software engineering best-practices and CICD are easier to put in place. So we created a k8s-based, multi-cloud, multi-cluster productivity tool build by developers for developers. End-users interact with Conveyor through a command-line interface (CLI) and a web-based user interface (UI). The CLI is used throughout the building and deploying of data projects, while the UI is mostly used in the run phase. ​ The control plane is hosted by Data Minded. It is middleware between the users and the data plane. It is responsible for cross cutting concerns like user authentication and authorization, state management, cost aggregation, ... . ​ The data plane is the Kubernetes-based managed infrastructure that runs within your own cloud environment. It consists of multiple services that takes care of provisioning and scaling the needed infrastructure and everything related to the scheduling of the execution of data projects. Conveyor has two simple concepts: projects and environments. A project is code, a unit of deployment (architectural quantum) that describes the what and how it needs to be executed.   Environments are isolated segments in the infrastructure where a data project can be deployed and executed. Create a batch pipeline often used for analytics to periodically collect, transform and move data to a data warehouse according to business needs. Templates for various technologies and use case, get you started with just a couple of key strokes. Using the remote execution `run` command, you can execute your code remotely in the right context. Create persistent or throw-away environment. Select a resource size and a security context. Deploy and promote data project with ease. Once your data project is deployed, you want to follow-up on resource utilization, cost and troubleshoot potential failures. An environments links to a Kubernetes clusters deployed as part of the customers data plane. Customers can have multiple clusters spread over homogeneous or heterogenous cloud accounts. Create paved roads, take care of boilerplate and encourage the use of best practices across teams. Clients can create their own templates based on their needs, and the systems they integrate with. Jupyter notebooks are well known for their ease in data exploration and experimentation. Data Minded cloud notebooks are build on the same containerization foundation as data project code. This enables other use cases e.g. using notebooks to debug and facilitate iterative industrialization of experiments. Each environment has a dedicated Apache Airflow instance for batch workload orchestration. Automated client-side DAG validation. Some projects need more power that can be provided by a single node. Data Minded Cloud offers Apache Spark (batch and streaming) as a first class citizen. To operate data projects, logs and metrics are centralized and available in real-time. For some integrations, access to the technology native UIs are available e.g. Apache Spark History Server. Follow your cloud cost per project over time. Gain insight into cost distribution across projects and environments. Authenticate users with your own identity provider. Control the actions any user can perform on projects and environments using role-based mechanisms. Each project can be linked with cloud specific IAM credentials. This link is enforced so that each job can only access those resources it was granted access to. Combined with the RBAC model on environment and projects, data access management is in your hands. Consulting Conveyor Product & Features Comparison Docs Academy Our offering Resources Cases Blog About us Team Join us Cloud Partnerships Pricing Vismarkt 17, 3000 Leuven, Belgium info@dataminded.be Vat. BE.0667.976.246 Consulting Conveyor Academy Resources About us More One of the first things that comes to mind to enable a team of data engineers and data scientists is to build your own data platform. Let us have a look at the pros and cons of that approach and how Conveyor can bring a fresh point of view to this subject. So you are about to start a new data project. They come in different shapes, but often, they resemble one of the following scenarios: ​Data pipelines, Machine learning, Data warehouse modernization. Each scenario requires you to build the data project itself and all the underlying infrastructure. From source control, to packaging and publishing your code, all the way to deployment, scheduling, and operations (logs, metrics, documentation, ...). Create a batch pipeline often used for analytics to periodically collect, transform and move data to a data warehouse according to business needs Once your use case is live, you need to look at cross-cutting concerns like cost management, update management, troubleshooting, security, access-control, ... We all know, the devil is in the details. Building a self-service infrastructure, making sure your developers don't spend all their time juggling between 10 different heterogeneous systems to work on their data product is not as easy as it sounds. It will take at least a few months and dozen of iterations to get it right. Operating, maintaining and extending your data platform comes at a significant cost Creating a full-fledge data platform takes a huge amount of time Once the infrastructure has landed, it's even harder to keep your projects live Conveyor is meant to be a centralized home for all your data projects, while preserving the freedom of each engineer or team to use their favorite tools or frameworks. You can get a head start on your data use-cases right using templates favoring software engineering best-practices. Use scaffolding and templates for projects as well as abstract away infrastructure Decrease time to market by streamlining application lifecycle Use monitoring and evergreen strategies to keep costs under control Consulting Conveyor Product & Features Comparison Docs Academy Our offering Resources Cases Blog About us Team Join us Cloud Partnerships Pricing Vismarkt 17, 3000 Leuven, Belgium info@dataminded.be Vat. BE.0667.976.246 Consulting Conveyor Academy Resources About us More Conveyor offers plans adapted to each type of user. ​ Plans range from Free, enabling you to start quickly, all the way to Enterprise, allowing you to meet strict compliance regulations.  Features ​ CLI​ ​ WEB UI ​ Templates   ​   users ​ projects ​ environments ​ clusters ​ core hours ​ ​ ​ Spot nodes ​ Batch jobs ​ Streaming jobs ​ Notebooks ​ ​ ​ Cost dashboard   RBAC ​ SSO ​ Roles ​ ​ ​ Productivity audit   cost audit ​ feature development ​ ​ ​ SLA   Support ​ Cloud ​ Free ​ ​ ​ ​ ​ ​ ​ ​   Unlimited ​ Unlimited ​ 1 ​ 1 ​ 5000 ​ ​ ​ ​ ​ ​ ​ ​ ​ ​ ​ ​ ​  ​  ​  ​ 1 ​ ​ ​  ​  ​  ​ ​ ​ Best effort   Community ​ AWS Cloud ​ Team ​ ​ ​ ​ ​ ​ ​ ​ Unlimited ​ Unlimited ​ Unlimited ​ 1 ​ Unlimited ​   ​ ​ ​ ​ ​ ​ ​  ​ ​ ​  ​  ​  ​ Multiple ​ ​ ​  ​  ​  ​ ​ ​ 99% ​ Standard 
AWS and Azure ​ Enterprise ​ ​ ​ ​ ​ ​ ​   ​ Unlimited ​ Unlimited ​ Unlimited ​ Unlimited ​ Unlimited ​ ​ ​ ​ ​ ​ ​ ​ ​  ​ ​ ​ ​ ​ ​ ​ ​ ​ Multiple ​ ​ ​ Quarterly ​ Quarterly ​ Prioritized  ​ ​ ​ SLA Tailored   Premium ​ Any cloud ​ The pricing is for the Conveyor platform only. It does not include pricing for any required cloud resources (e.g. compute instances, databases, ...). The baseline cloud cost for a single cluster is about 10 USD per day or about 300 USD per month. Unlimited users, projects Single cluster and environment 5000 core hours to play and try Single RBAC role AWS only Community support Everything on the free plan and Unlimited environments Unlimited core hours Cost dashboard 99% SLA uptime AWS and Azure Standard support Everything on the team plan and Unlimited clusters SSO support Multiple RBAC roles Productivity and cost auditing Custom SLA uptime Prioritized feature requests Premium support Any cloud Use the following steps to estimate the Conveyor and instance costs for a particular workload.  ​ Let’s say you have two environments (staging and production). Each environment runs 10 DAGs with each one an average of 20 tasks. We will calculate the monthly costs for only the production environment were the jobs run daily. ​ In our example, the 20 tasks are split into 2 types: 10 Spark jobs running one mx.small driver and five mx.medium executors for 30 min. 10 container jobs running one mx.medium instance for 10 min. ​ Conveyor proposes multiple job compute types. In order to simplify calculations, we convert any types's number of hours of compute back to equivalent mx.medium hours. By definition, this type has 1 cpu core and 4 GiB mem. ​ The mx.small has 0.5 cpu cores, so this means that 1 hour of this instance is equivalent to 0.5 hours of an mx.medium.   Let’s do it for the production environment. ​ Spark hours Spark executor: 10 DAGs * 10 tasks * 5 executors * 1/2hour* 30days = 7500 mx.medium hours Spark driver: 10 * 10 * 1/2 hours *30 = 1500 mx.small hours = 750 mx.medium hours. ​ Container hours Container jobs: 10 * 10 * 1/2 hours *30 = 1500 mx.medium hours ​ Total hours Monthly you will use 9750 mx.medium hours. ​ The Conveyor license costs are computed in core-hours. Because the mx.medium has a single cpu core, you can reuse the total amount of mx.medium hours without any additional multiplication. ​ For the production environment this means that 9750 instance hours will cost you 487.5 EUR in licensing cost for one month using the Conveyor Team plan. ​ An mx.medium job is a Conveyor concept. The underlying Kubernetes cluster itself can run on many types of instances. Kubernetes will scale the number of actual worker nodes for you based on the required number of cpu cores and memory. This means that for an estimation, you will need to roughly convert the mx.medium (1 cpu, 4 GiB mem) to the actually provisioned cloud instance.   Let’s say on AWS a mx.medium job is running on a m6i.mxlarge (4 cpu, 16 GiB mem) instance with an hourly cost of 0.214 EUR. A single mx.medium job hour is then roughly equivalent to 0.25 of a m6i.mxlarge hour, thus costing 0.0535 EUR per hour. ​ For our production environment, this means that the 9750 instance hours results in a cost of 521.63 EUR when running on-demand. ​ If you would run on spot instances, we can reduce this cost up to 90%, but let’s take a more conservative 70% reduction: 156.48 EUR. ​ This principle is the same on any cloud provider. The total conveyor cost is the sum of the license and the cloud cost. ​ Our monthly total cost for the production environment would be 1009.13 EUR when running on-demand, and 643.98 EUR when running on spot instances. Consulting Conveyor Product & Features Comparison Docs Academy Our offering Resources Cases Blog About us Team Join us Cloud Partnerships Pricing Vismarkt 17, 3000 Leuven, Belgium info@dataminded.be Vat. BE.0667.976.246 Consulting Conveyor Academy Resources About us More Consulting Conveyor Product & Features Comparison Docs Academy Our offering Resources Cases Blog About us Team Join us Cloud Partnerships Pricing Vismarkt 17, 3000 Leuven, Belgium info@dataminded.be Vat. BE.0667.976.246 Consulting Conveyor Academy Resources About us More When you want to transform data into value, you have 2 options: either you outsource this process to experts, or you attempt to do it yourself. Since technology is ever evolving at enormous speeds, the latter might be hard since you might not have the know-how internally.   At Data Minded, we help you with the value extraction process in both ways: you can use our consultancy services, or improve with our academy services. With the academy, our shared intent is to make you more capable in record time. We offer workshops on key technologies and data challenges that are common in even the best data driven companies. We not only organise workshops for our clients but also teach at different business schools. Some of our thoughts and findings are captured and accessible through our Youtube channel. In addition, we organise yearly Winter and Summer schools, lasting one week, in which we dive deep into several key technologies. In short, there’s something for everyone! Have a look at our catalog of ready-to-go courses. Tag along in one of our workshops scheduled at predetermined dates. By subscribing you will be able to participate in a 1 to 3 day workshop , depending on the topic, where our experienced instructors will not only help you to grasp the essentials but also teach you the best practices of fundamental technologies, key concepts and modern techniques related to data and engineering. Twice a year we organise a week full of interactive workshops led by our experienced instructors. The content is a carefully selected subset of our standard courses, reduced in length to fit within one week. As cherry on the cake, we end the week with a capstone exercise in which participants get to combine all they’ve learnt in that week in one coherent package, combining several cloud services and technologies, illustrating many concepts of a modern data platform. Don’t want to wait for the courses and workshops that we offer at predetermined dates? Or are you in need of a tailored workshop that fits your business? No problem! Reach out to us to discuss a custom training program for your business. Remote or on-premises, we have experience with both approaches, and even run hybrid formats: with flipped-classroom trainings, participants watch the theory upfront, and then join the interactive sessions to have the material deeply ingrained. Classroom trainings Remote sessions On premise Consulting Conveyor Product & Features Comparison Docs Academy Our offering Resources Cases Blog About us Team Join us Cloud Partnerships Pricing Vismarkt 17, 3000 Leuven, Belgium info@dataminded.be Vat. BE.0667.976.246 Consulting Conveyor Academy Resources About us More The manifesto is a set of principles that will make sure your projects will be delivered on time, empower your people, and ensure the stability of your products. ​​ This is based on our collective experience from all of our projects. A data engineer creates software by writing code while following best practices. This includes adopting software design principles, version control, automated testing, CI/CD, Cloud-Native, and DevSecOps practices.  ​Without customers that actually use it or buy it, data is not generating anything. It is a product and we should treat it like one and measure how successful it is: usage, time-to-market, quality, availability, ...  As data engineers, we build custom data pipelines for complex use cases. For more common use cases we provide self-service solutions. We are an enabler in an organisation.  Public cloud providers have drastically changed the playing field of data engineering over the last few years. They have increased flexibility while lowering the operational burden. There are still valid exception scenarios but cloud is the new default.  While it might be more interesting to build a real-time data stream, it can add unneeded complexity (state, replay, ... ). If your use case only requires data once per day, keep it simple, keep it stupid, keep it sustainable! This doesn’t mean we shy away from stream processing when needed. ​Consistency is a powerful weapon yet there is no golden hammer. For each use case, we try existing “boring” technologies first, rather than selecting a technology to expand our own knowledge and experience. We will use bleeding edge technology when we have good reason to do so. Notebooks bring value at the beginning of a data product when exploring data,  looking for potential solutions and documenting along the way. The structure of notebooks does not incentivize good software design patterns though. So once you are done exploring, a proper IDE is the right tool for the job.  Data engineers and data scientists share a common technology stack, yet they often play a different role in the organization. This can lead to a dysfunctional marriage but it doesn’t have to. We work together and see the best results emerge in cross-functional teams.  Over the years we have seen the rise of domain-specific languages and drag-and-drop tools. Nothing has come close to the expressiveness and adoption of SQL. We see it as the bridge to enable less technical profiles and we favor it as the interface in self-service solutions.  ​ Check out the webinar to have more in-depth ideas about the  Data Minded Manifesto. Consulting Conveyor Product & Features Comparison Docs Academy Our offering Resources Cases Blog About us Team Join us Cloud Partnerships Pricing Vismarkt 17, 3000 Leuven, Belgium info@dataminded.be Vat. BE.0667.976.246 Consulting Conveyor Academy Resources About us More Data maturity demonstrates the level at which a company makes the most out of its data. The more data mature a company is, the more data efforts become interconnected with different aspects of the organisation. 
Whether you're aiming for innovative AI/ML products or are more focused on data analytics, you'll need the right data engineering efforts to create an underlying future-proof data platform.   Determine whether you are on the right track using the tool below, so you can take action right away! Our Data Maturity Scan will quickly give you an idea how good your company scores. ​ Answer 6 questions by selecting which practices currently apply within your company. 
  Get insights into how data mature your organisation is and on which categories your company scores well.
  ​Compare your score with industry benchmarks.
  Get started on improving your data maturity by following the tips from our whitepaper. Consulting Conveyor Product & Features Comparison Docs Academy Our offering Resources Cases Blog About us Team Join us Cloud Partnerships Pricing Vismarkt 17, 3000 Leuven, Belgium info@dataminded.be Vat. BE.0667.976.246 Consulting Conveyor Academy Resources About us More Introducing cloud for doing ML training at scale Industrialising ML use cases with a central Data & Analytics platform (“NEO”) and long-lived business teams. Datafy is at the heart of NEO.  Scaling advanced analytics to continuously improve customer experience of media products Implementing more accurate sales forecasting to drive more efficient operations Setting up a SaaS product on AWS. Leveraging cloud scalability to meet client demand. Consulting Conveyor Product & Features Comparison Docs Academy Our offering Resources Cases Blog About us Team Join us Cloud Partnerships Pricing Vismarkt 17, 3000 Leuven, Belgium info@dataminded.be Vat. BE.0667.976.246 Consulting Conveyor Academy Resources About us More Conveyor is Data Minded's managed, cloud-based data platform for building and running secure and reliable data products. Unlike many other platforms, Conveyor focuses on removing the infrastructure and process barriers that are typically encountered in the lifecycle of a data project.  During this webinar, we introduce Conveyor and talk about why we built it. We will also dive into a concrete data product usecase and go through the various lifecycle stages of the data product development using Conveyor, and highlight how it helps you along the way.  Understanding the ambitions and the current data maturity level is crucial before starting or continuing your data journey. Therefore Data Minded developed a Data Maturity Index that helps you visualize the balance in your data organization. Not only is the Data Maturity Index helpful to focus on the actual bottlenecks and set priorities, it also is a benchmark to visualize the impact of engagements and transformations. During this webinar you will learn: → What data maturity is and how we came to the Data Maturity Index → Why you should (or should not) grow your data maturity → Who the people behind the Data Maturity Index are   Test your data maturity Many data projects begin and end with experimental code running in a notebook. But when you have to support the code in production, you often hit the limitations of notebooks. These limitations are hard to maintain, hard to debug, hard to reuse and hard to extend.   So you need to look for ways to package and deploy your code in a more consistent, reliable way. And this is exactly why containers have taken the software engineering world by storm and why the data world is seeing a rapid adoption of container technology. In this webinar we will take you, step by step, through the process of converting a classical python or spark notebook into a reliable, scalable and portable container that can run on any cloud or even on your laptop. We will use open-source templates to help you get started and clarify some of the magic that goes on behind the scenes. Do you want to be kept informed about our upcoming webinars?  Fill out your email address and we will send you invites for our upcoming webinars.  Consulting Conveyor Product & Features Comparison Docs Academy Our offering Resources Cases Blog About us Team Join us Cloud Partnerships Pricing Vismarkt 17, 3000 Leuven, Belgium info@dataminded.be Vat. BE.0667.976.246 Consulting Conveyor Academy Resources About us More Partner - CEO Engagement Manager Datafy Lead  Data Engineer Data Engineer Data Engineer Data Engineer Data Engineer  Marketing Manager Partner - CTO Engagement Manager Office Manager Data Engineer Data Engineer Data Engineer Data Engineer Data Engineer Data Engineer Partner - COO Head of Data Minded Academy Office Manager Data Engineer Data Engineer Data Engineer Data Engineer Data Engineer Consulting Conveyor Product & Features Comparison Docs Academy Our offering Resources Cases Blog About us Team Join us Cloud Partnerships Pricing Vismarkt 17, 3000 Leuven, Belgium info@dataminded.be Vat. BE.0667.976.246 Consulting Conveyor Academy Resources About us More Excited about Data Minded and what the team accomplishes together with clients? Ready to use your skills, passion and drive to strengthen our team of data engineering specialists? Check out our career opportunities and give us a shout. At Data Minded, data engineers are at the heart of what we do. As part of our young and fast-growing team based in Belgium, you take part in complex data analytics projects through their entire lifecycle.  Consulting Conveyor Product & Features Comparison Docs Academy Our offering Resources Cases Blog About us Team Join us Cloud Partnerships Pricing Vismarkt 17, 3000 Leuven, Belgium info@dataminded.be Vat. BE.0667.976.246 Consulting Conveyor Academy Resources About us More At Data Minded, we strongly believe in Cloud. Cloud allows organizations to scale quickly and elastically, and focus on their core business. Our data engineers are highly knowledgeable about the different services offered by the major cloud providers, and can help your organization to leverage their capabilities to the fullest.  We are proud partners of the main three public cloud providers: Amazon Web Services (AWS), Microsoft Azure, and Google Cloud Platform (GCP). Our partnerships allow us to stay ahead of the curve, and serve our clients with bespoke solutions that fit their needs.  With more than 20 AWS certificates, including various specializations such as security, data analytics, machine learning,… and over 20+ projects successfully built and deployed on the Amazon cloud, it's safe to say we know the ins and outs of what AWS has to offer. From containers on EKS, to streaming with Kinesis, to AI/ML with SageMaker: together with our clients, we can build state-of-the-art data platforms and products. 
Check out our AWS partnership page, and get a taste of what we can do for you via our AWS customer success stories. Scheduling pipelines with Azure Data Factory, training machine learning models on Azure ML, managing identities and access rights at enterprise scale with Azure AD,… several of our clients rely on these core services of Microsoft's cloud. Whether you are just at the start of your cloud journey, or an already experienced cloud organization, Data Minded can help you with your Azure endeavors at scale. ​ You can find us in the Azure Partner directory. Google Cloud Platform is home to some of the most loved cloud services out there. Whether you want to extract insights from large amounts of data with BigQuery, build a truly serverless streaming application with PubSub, or harness Kubernetes' flexibility without its complexity with GKE, GCP has got you covered. We, at Data Minded, enjoy coming up with creative solutions that leverage these services in order to help our clients succeed. ​ You can find us listed as an official partner on our GCP Partnership page. Consulting Conveyor Product & Features Comparison Docs Academy Our offering Resources Cases Blog About us Team Join us Cloud Partnerships Pricing Vismarkt 17, 3000 Leuven, Belgium info@dataminded.be Vat. BE.0667.976.246 Consulting Conveyor Academy Resources About us More At Data Minded, data engineers are at the heart of what we do. As part of our young and fast-growing team based in Belgium, you take part in complex data analytics projects through their entire lifecycle. Besides design and implementation, this also includes following up on project schedules, identifying risks and clearly communicating them to project stakeholders. ​ You're interested in helping organisations become data minded and your idea of fun involves scalable compute clusters or massive data processing. You are convinced sensor data and IoT will have a big impact on society in the coming years and you want to be part of that shift. You are a fan of open source technology and you are not blind to its pitfalls. You are eager to learn and you like to work in a dynamic, no-nonsense start-up environment. Data Minded is a fast-growing team, passionate about data. We are all engineers. We all write code on a daily basis. We put our people ahead of our products and our products ahead of our profits. We choose long-term gains over short-term profits. We are big believers of open source, cloud technology and IoT. We are based in Leuven. ​​ Data Minded has grown from an idea to becoming a local leader in data analytics. We have delivered several successful projects in the areas of telecom, healthcare, biotech and others. We provide technical training to the community and advise large corporations on how to approach data projects. To achieve these results, we keep an open mind, we adapt fast and we always tell the truth as we see it. We coach and mentor each other. We learn from our mistakes and share our learnings. Architect, develop and deploy a wide range of data applications, both on-premise and in the cloud ​ Design complex analytics solutions with large data sets on distributed systems ​ Work independently, prioritize multiple stakeholders and tasks, and manage work time effectively. ​ Provide thought leadership for clients and partners to help them understand the data analytics landscape Bachelor in Computer Science or related technical field, or equivalent practical experience. ​ Programming experience with one or more languages: Python, C#, Java, Scala, C/C++, ... ​ Basic understanding of databases and SQL ​ Linux experience ​ Highly proficient in spoken and written English MS/PhD degree in Computer Science, Math or a technically oriented field. ​ 5 years of relevant experience in software development, solution engineering, technical consulting; with expertise in architecting and rolling out new technology and solution initiatives. ​ Experience with big data technologies (such as Hadoop, Spark, Cassandra, Elasticsearch) ​ Excellent coding skills and deep knowledge of SQL ​ Knowledge of data science and machine learning algorithms, on large data sets. ​ Good understanding of cloud possibilities and limitations in the areas of distributed systems, load balancing and networking, massive data storage, and security. ​ Able to mentor junior members and give technical advice and direction. ​ Knowledge of Dutch and/or French Then we would love to talk with you! Get in touch by sending an email to 
careers@dataminded.be Consulting Conveyor Product & Features Comparison Docs Academy Our offering Resources Cases Blog About us Team Join us Cloud Partnerships Pricing Vismarkt 17, 3000 Leuven, Belgium info@dataminded.be Vat. BE.0667.976.246 Consulting Conveyor Academy Resources About us More Introducing cloud for doing ML training at scale BICS is a communications platform company providing international communications, messaging and connectivity to operators and enterprises, globally. BICS relies heavily on ML predictive analytics in several use-cases: to forecast pricing evolution, combat fraud, analyse mobility, etc. Most of the data processing and analytics is happening in a local data center, BICS wants to experiment with a hybrid setup, where some ML jobs run in the cloud. The main benefits of the cloud in this context is scalability and cost efficiency. execute one ML use-case in the cloud, fully integrated into the existing data processing framework Adapt the existing software tooling (CI/CD, scheduler, network connectivity) to work with cloud resources. We set up a machine learning environment on AWS, leveraging SageMaker. Model predictions, model training and also hyperparameter tuning jobs are all running on SageMaker. The SageMaker jobs are integrated with the on-premises scheduler, and data flows seamlessly between on-premises network and the cloud. Scalability of the cloud means that BICS can run on-demand ML tuning jobs, while keeping their existing on-premises cluster for scheduled jobs This drives more innovation and experimentation, resulting in a more scalable and sustainable way-of-working for their data scientists Consulting Conveyor Product & Features Comparison Docs Academy Our offering Resources Cases Blog About us Team Join us Cloud Partnerships Pricing Vismarkt 17, 3000 Leuven, Belgium info@dataminded.be Vat. BE.0667.976.246 Consulting Conveyor Academy Resources About us More Introducing cloud for doing ML training at scale Industrialising ML use cases with a central Data & Analytics platform (“NEO”) and long-lived business teams. Datafy is at the heart of NEO.  Scaling advanced analytics to continuously improve customer experience of media products Implementing more accurate sales forecasting to drive more efficient operations Setting up a SaaS product on AWS. Leveraging cloud scalability to meet client demand. Consulting Conveyor Product & Features Comparison Docs Academy Our offering Resources Cases Blog About us Team Join us Cloud Partnerships Pricing Vismarkt 17, 3000 Leuven, Belgium info@dataminded.be Vat. BE.0667.976.246 Consulting Conveyor Academy Resources About us More Industrialising ML use cases with a central Data & Analytics platform (“NEO”) and long-lived business teams. Datafy is at the heart of NEO.  Luminus is the second largest electricity producer and energy supplier on the Belgian energy market. In 2019, Luminus successfully started experimenting with machine learning, but had no experience with operating machine learning use cases. The Luminus’ technology stack was built for traditional business intelligence, on on-premise infrastructure. Set-up an operating model and cloud-native data & analytics platform which allows to build and run machine learning applications, leveraging on self-service. Implementation of a new IT-oriented Landing Zone and Data & Analytics Platform capabilities​, based on Data Minded Cloud. It covers the full machine learning workflow from experimentation to monitoring, and required design patterns (batch processing; streaming). We have set up long-lived business-oriented use cases teams, including new roles across business lines and IT. This new way of working helped to establish a culture of increased ownership, innovation and learning. Within one year, 25+ users (scientists and engineers) were on-boarded, 7 use cases went live; 18 projects have started; 21 data sources were connected. Positive ROI after delivery of first use cases. Widespread adoption of data platform in different business lines. Continued value-driven industrialisation of new use cases. Strong cultivation through Data Minded Academy. Consulting Conveyor Product & Features Comparison Docs Academy Our offering Resources Cases Blog About us Team Join us Cloud Partnerships Pricing Vismarkt 17, 3000 Leuven, Belgium info@dataminded.be Vat. BE.0667.976.246 Consulting Conveyor Academy Resources About us More Scaling advanced analytics to continuously improve customer experience of media products DPG Media is a leading media group with activities in Belgium, the Netherlands and Denmark. DPG Media owns several popular brands in newspapers & magazines (Het Laatste Nieuws, De Morgen, Humo), radio & television (QMusic, VTM) and online services. DPG Media has the ambition to become the local leader in the media landscape and therefore decided years ago to make the full switch to cloud, to invest in mobile and digital products with HLN Mobile and VTM GO, the Flemish Netflix as an example. Advanced analytics powered by artificial intelligence and machine learning are an instrumental tool for DPG to continuously improve customer experience of its media products. Since early 2017, Data Minded has been a trusted partner of the data lake team, enabling the entire organisation to create self-service use cases for data analytics and successfully rolled out Datafy as a managed data engineering platform The team is responsible for maintaining the central data platform, from infrastructure and workflow management to delivering data products, data science workbenches and reporting tools to the rest of the organization. In addition, they are also responsible for ingesting and processing major batch and streaming data sources such as CRM, clickstream, advertising, sales and marketing data. Data Minded also provides training and advice on data architecture. The platform technology stack mainly consists of open-source software components such as Scala, Python, Airflow, EKS Kubernetes, CodeBuild/CodePipeline, Terraform, Gradle, Kafka, Elasticsearch, and many more, all built on AWS cloud. Within one year, 600+ users (scientists and engineers) were on-boarded,  50+ use cases went live; 2800 projects have started; 60+ data sources were connected. This degree of adoption was only possible by rethinking the way of working: Harmonising processes and tools across Belgium and the Netherlands, Cloud migration, Managed cloud-native data engineering platform, A central data repository for all teams for data discovery, data governance and data sharing. DPG Media & Data Minded succeeded in creating a complete 360° view of its customers by combining both online and offline data to provide personalised recommendations for their media products. In addition, rethinking the way of working improved operational efficiency, reduced legacy and thus improved costs. Consulting Conveyor Product & Features Comparison Docs Academy Our offering Resources Cases Blog About us Team Join us Cloud Partnerships Pricing Vismarkt 17, 3000 Leuven, Belgium info@dataminded.be Vat. BE.0667.976.246 Consulting Conveyor Academy Resources About us More Implementing more accurate sales forecasting to drive more efficient operations Newpharma is market leader in Belgium and France in online pharmacy and plays a prominent role on the European market. The company reached out to Data Minded to help kick off its analytics transformation. The project started off with the case of predicting future sales. In the past, Newpharma steered the planning of its logistics operations workforce using basic sales forecasting models enriched with market and process experience. As the number of its customers and products increased dramatically, Newpharma decided to look for a more data-driven and scalable approach to forecast sales and organize its operations. In a first two-week period, we have explored a wealth of data (historical sales, product catalogue, marketing campaigns, weather, etc.) as well as different predictive modelling techniques. Subsequently, we were able to outperform the legacy model using the acquired information and insights. ​ After this positive result, Data Minded has designed and implemented a data platform based on AWS Cloud, Airflow, Spark and Python to train and run an LSTM model on a daily basis and publish order predictions. Kubernetes is used as an orchestration solution for automating and scaling infrastructure and applications. On average, the new predictive model engineered by Data Minded is 33% more often within the ±10% error range compared to the existing legacy approach. In addition, the end-to-end data processing and analytics is now fully automated. The Data Minded specialists succeeded in completing the entire project within a period of two months. The stream of consistently more accurate sales predictions enables Newpharma to streamline its operations accordingly. Considering the large scale of Newpharma's operations, this involves expenditure savings that are huge. The scalable and structured approach of Data Minded intrinsically leads to a more efficient and targeted use of human resources. Consulting Conveyor Product & Features Comparison Docs Academy Our offering Resources Cases Blog About us Team Join us Cloud Partnerships Pricing Vismarkt 17, 3000 Leuven, Belgium info@dataminded.be Vat. BE.0667.976.246 Consulting Conveyor Academy Resources About us More Setting up a SaaS product on AWS. Leveraging cloud scalability to meet client demand. Kwarts is a start-up in the area of life science and medical affairs. Their SaaS product, A-Inside, helps pharmacological companies with their customer relationship: offering the most relevant product at the appropriate time via the best communication channels. Setting up a cloud-based architecture for data analytics Setting up the data processing pipelines at one client Setting up the environment for the in-house developed state of the art machine learning models Setting up the SaaS user interface at one client Enabling efficient scaling to m clients in short term The supporting AWS infrastructure was set up and configured Data ingestion pipelines were developed and deployed at one client Integrating the SaaS product: data ingestion, ML predictions and displaying the results Pilot of the SaaS product is running at 1 client Demos of the product at multiple clients Consulting Conveyor Product & Features Comparison Docs Academy Our offering Resources Cases Blog About us Team Join us Cloud Partnerships Pricing Vismarkt 17, 3000 Leuven, Belgium info@dataminded.be Vat. BE.0667.976.246 Consulting Conveyor Academy Resources About us More Databricks is one of the most popular tools for building and running SQL, python and R notebooks. It provides a great way to get started and experiment with your first data pipelines. Conveyor focuses primarily on delivering high quality data products which is not possible through only a notebook environment. Notebooks are great for experimenting and creating a first version of your code due to it's interactive environment but they have several drawbacks for writing production code: No modular code
Difficult to share code as well as as navigate across multiple notebooks in the Databricks UI
  No tests
No easy way to write tests and thus protect against regression
  Not reproducible
Dependent versions of python, Spark are not specified in the notebook but in the Databricks cluster
  No configuration parameters/files
Managing configuration is difficult, Databricks only provides the dbutils package but this is not portable outside Support both notebooks and IDE
Use notebooks for experimentation but your IDE to write modular and easy to maintain code
  Add tests to your code
  Docker image
Code is packaged with all dependencies to make it truly build once, deploy anywhere
  Airflow dags
Airflow configuration can use environment variables, extra arguments to customize your code Databricks has poor support for creating data pipelines: Managing tens or a hundred of data projects with Databricks is both challenging as well as costly:​ Data access on a workspace
All notebooks in the same workspace can access the same data. To separate them by using different workspaces
  Databricks clusters per team
In order to make teams independent, they need their own cluster as it defines the python, spark,... versions 
  Databricks licence fee of 50-80%
On top of the raw compute cost of your cloud provider
  Use latest source code in job
A job in Databricks runs the latest version of your notebook, which is not necessarily the latest committed code
  Job dependencies
Limited support to express depencencies between notebooks
  Notebook dependencies
Many library, framework versions are defined on cluster level instead of in your notebook 
  No overview on all jobs
Difficult to monitor all jobs of a given day Docker image
All code and depencencies are packaged in a docker image such that you know exactly which version is being executed by your job.
  Airflow
Airflow has extensive support for defining complex Dags as well as a UI with an overview of jobs
  Notebook dependencies
Many library, framework versions are defined on cluster level instead of in your notebook  Data access per project
We support the principle of least privilege by linking data access to project/job
  RBAC (role-based access control)
is used to define permissions for users on projects/environments
  Cost dashboards
Give insights into costs in order to reduce them  Databricks added support for Repositories which is a big improvement to manage multiple notebooks. There are however still 2 major issues when collaborating with multiple people: git is not a first class citizen
You can not make changes to the same file with multiple people at the same time 
  Cannot develop notebooks from your IDE
When working with multiple people, you need a premium cluster which does not support connecting to it from your IDE Native GIT integration
Create feature branches and merge changes when working with multiple people on the same files Consulting Conveyor Product & Features Comparison Docs Academy Our offering Resources Cases Blog About us Team Join us Cloud Partnerships Pricing Vismarkt 17, 3000 Leuven, Belgium info@dataminded.be Vat. BE.0667.976.246 Consulting Conveyor Academy Resources About us More EMR is the default way to run Spark Jobs on AWS. It's a stable environment with a genuinely fast runtime. The main differences with Conveyor are: ​ Know and configure AWS infrastructure details
Manually configure VPC's, IAM roles etc
  No 1 way to use notebooks
EMR studio, EMR notebooks, Sagemaker are candidates
  Configure a tool to manage workloads
Use managed workflows for AIrflow, Step functions or a homebrew solution
  Conveyor environments with managed Airflow
Schedule containers or spark jobs on the cluster
  Notebooks for experimentation
Explore data or test ML algorithms with one command
  Conveyor run command
Start Spark or container jobs on the cluster from your local environment In EMR, you have to create and manage a cluster to schedule your jobs.​ IAM roles are linked to a cluster
Use 1 cluster per job if you want to use different IAM roles
  Clusters do not autoscale by default
  Clusters do not update automatically
  Clusters are bound to spark/hadoop versions
When sharing a cluster, all applications need to be updated at the same time
  Creating a cluster takes up to 15 minutes
  EMR on EKS
Manage the EKS data-plane with all components yourself Conveyor manages clusters for you
  One cluster for all jobs
Each job can use a separate IAM role
  We run containers
Run the same container locally or anywhere else
  Mix spark/hadoop versions on one cluster
All dependencies are packaged in docker containers Any job type existing in the Hadoop ecosystem
Spark, Pig, Hive, etc are supported
  (Too) many ways to package code
Jars, pyfiles, pex distributions, containers,...
  No support for non Hadoop jobs
Cannot run simple python code Any container can be run non-distributed
Use your favorite programming language
  Use spark for distributed jobs
For processing large volumes of data
  DBT for data warehouse transformations
lower the barrier for data analysts to use and process data Consulting Conveyor Product & Features Comparison Docs Academy Our offering Resources Cases Blog About us Team Join us Cloud Partnerships Pricing Vismarkt 17, 3000 Leuven, Belgium info@dataminded.be Vat. BE.0667.976.246 Consulting Conveyor Academy Resources About us More From destination unknown to a guided data journey A solid data strategy, architecture and infrastructure allow organizations to focus efforts on where it matters most i.e. value creation. What makes your organization stand out to competition? What is your customer paying for? Where can you improve the customer journey with innovative services or democratize your product and services? If it is not adding value to your customer, ask yourself if it is really needed or if another party can do it better. Continuously making these reflections helps you to grow your core business.    Data Minded helps to drill down to your core business value and create an achievable plan for the future. It always starts with a profound understanding of the corporate & digital ambition, and how data & analytics enable this ambition. Based on the ambition and current data maturity level every organization has different needs and has to set different priorities. Practice shows that it is not always easy to look at the bigger picture when you need to keep the lights on, pressure is put on teams to continuously deliver new use cases and budgets are challenged. As a result companies often use a certain technology or process until it is end-of-life and are confronted with complex transformation programs.    If you recognize one of the following pain points, the time might be right to start a data strategy exercise or reassess your current architecture: ​ Misalignment between IT, data & analytics and business High dependency on legacy systems and  Difficulties to attract skilled data & analytics profiles Data products that don’t get industrialized Drift of ML model performance is not monitored ​ Start the journey with our experienced guides At Data Minded, we support our clients in achieving their data ambitions. Data Minded offers data strategy, data architecture and cloud infrastructure services to help organizations get the most value possible from their data.     Working with Data Minded allows you to leverage industry best practices and take a head start. Together we ensure there is a solid foundation to create long term business value. This foundation is best represented by the AI hierarchy of needs. ​ Our end to end knowledge has proven to be an important asset to guide clients to the top. Data Minded has a structured methodology to translate the corporate and digital strategy towards your data organization. We start from the value question and work towards an achievable roadmap. We go further than your techstack definition and creates a holistic view on your current and desired data & technology capabilities and operating model. We look at following dimensions: Last but not least we also aim to build engagement on all levels of the organization during our data strategy exercise. Data Minded does this by organizing thought leadership and best practices workshops transversely across dimensions & phases. In these workshops we inform and inspire you on topics such as data mesh, cloud architecture, BI best practices, streaming, machine learning, self service,... .   We believe that applying this methodology in an inclusive way in your organization, helps you build the required engagement to build and run a sustainable and scalable data organization. Whereas a data strategy helps you translate the corporate and digital strategy towards your data organization, the data architecture study has as an objective to clarify the how of your data strategy.   Together with the IT and data & analytics teams we define the technical landscape and operating model and have a detailed look into all dimensions: We address topics such as how to go cloud native, how to deal with security, which concepts are needed for implementation (a data warehouse, an event streaming system, …), how to do logging and monitoring, what is the ideal organization and corresponding roles & responsibilities? Going from your current situation to the desired state implies that you also have to deal with different types of constraints e.g. budget, legacy systems, culture,... . Together we set priorities, create a business case and define a roadmap. Often also a Proof of Concept is performed to ensure feasibility of the data architecture. Organizations often decide to go to the cloud. Most prominent reasons mentioned by cloud service providers are: At Data Minded we strongly support organizations that move to the cloud for the above mentioned reasons. One would even think that the hardest part is over when the decision has been made to move to the cloud. However, experience has taught us that this is only the beginning of a complex journey. An organization that migrates to the cloud using mostly IaaS is doing a so-called 'lift-and-shift', or a copy-paste of their existing infrastructure. This gives you a lot of flexibility and control, and because basically every cloud provider has an IaaS offering, it is considered to be a commodity, and the markup of these services is quite low. However, you should not underestimate the time it will take you to actually set everything up and to manage the patching and updating of the OS and other software. In addition to IaaS, most service providers also take patching and software maintenance related work out of your hands with Platform-as-a-Service and Software-as-a-Service offerings.    Together with your technical team we plan the migration step by step whilst actively managing security, cost and time. Our experts provide you industry and technology best practices.  Consulting Conveyor Product & Features Comparison Docs Academy Our offering Resources Cases Blog About us Team Join us Cloud Partnerships Pricing Vismarkt 17, 3000 Leuven, Belgium info@dataminded.be Vat. BE.0667.976.246 Consulting Conveyor Academy Resources About us More Unlock the full potential of data The ultimate goal of every organization is to base strategies, tactics and decisions on insights that are not available to competition in order to create a competitive advantage. Achieving this is only possible when everybody and every system in an organization has access to the right data to create value added insights. Or in other words “data democratization”: ​ “Everybody has access to data and there are no gatekeepers that create a bottleneck at the gateway to the data. The goal is to have anybody use data at any time to make decisions with no barriers to access or understanding.” - Bernard Marr What if we tell you that this ultimate goal is achievable for everybody who puts the right effort in growing the data maturity. ​ Do you recognize these challenges on your way to data democratization? What pipelines and platforms need to be set-up to enable self service analytics Which dashboards and data visualization tools integrate best with the current tech stack What is the most optimal way to store & model my data: data warehouse vs data lake, data vaulting How should I set-up data governance, access & security Which training is required to improve data literacy of data & analytics teams and business   These are exactly the challenges we can tackle together so you can benefit from the advantages of data democratization: easily discover and access data, better and faster decision making and enforced security & compliance. Democratizing data within your organization requires action in 5 dimensions.  The objective of Data Minded is that our customers achieve their objective in a pragmatic and cost efficient way. Our clients can count on our expertise in every phase of their journey. 1. Self Service Analytics 2. Dashboards & Data Visualisation According to Gartner, Self-Service Analytics is a form of business intelligence (BI) in which line-of-business professionals are enabled and encouraged to perform queries and generate reports on their own, with nominal IT support.    Accomplishing this requires years of careful planning and a complete rethinking the enterprise data systems and architecture. Actually, it’s broader than merely a choice of tools. Processes, people and how you think about a product will need to adapt as well.    Data Minded can help you identify and visualize the areas that will help you reach a functional level of self-serviceness. We do this typically using our data maturity framework as a guideline. This can serve as a basis for your data strategy for the coming years. Creating value from data, necessitates converting raw data into data insights that are understandable and actionable to everyone. While other data management tools may make data more accessible, dashboards and data visualization tools (e.g. Tableau,  PowerBI, Data Studio) facilitate interpretation. ​ Data Minded helps to select the data platform that will feed the visualization tools. The number of vendors and platforms you could consider is huge. Based on what we saw at previous clients, Data Minded is in a unique position to form a neutral recommendation and accelerate the implementation and adoption. 3. Data Storage & Modelling Multiple options exist to structure your data to facilitate analytics i.e. a data warehouse, a data lake or a hybrid form called a data lakehouse. Each has their own pros and cons. https://www.fivetran.com/blog/what-is-a-data-lakehouse    There is not one version of the truth and organizational needs change when higher levels of data maturity are achieved. Often not only the data structure is changed but also the underlying infrastructure could be impacted when combined with a cloud migration. Much debate has been had about data modeling in the modern data space. Traditional  dimensional (star schema) modelling allows for fast and simple queries and is well suited for typical reporting needs. On the other hand, it isn’t all that flexible. Techniques like data vaulting add an additional layer of complexity which might sometimes be worthwhile.  4. Data Governance, Access & Security It is essential to make sure the data managed by your organization is protected and easy to access. Even more so when dealing with client data. Optimally managing enterprise data offers different advantages: ​ Access to high-quality data to improve the quality of analyses Secure and compliant with regard to regulation Consolidate data across multiple sources for increased efficiency Easily identify data dependencies and users of data sources
  Data Minded helps to make the right governance and security choices on every level of your tech stack. Data Minded doesn’t only ensure you have the right tools (e.g. Collibra, Datahub, Great Expectations, AWS IAM, etc.) and fit with your overall architecture, but also implement the right processes. Fundamentally, Data Minded believes in a decentralized data landscape following data mesh principles. Each team delivers its own set of data products which can be consumed by other teams in the organization. There is no one global data model for the entire organisation. Instead, each department models the data to their needs. New data products can be created to reuse those models. Eg: A customer360 view or a dimensional model of finance data. Data Minded has already implemented data warehouses and data lakes in multiple organizations. Before implementing changes, a deepdive is performed on the current challenges and needs. By looking at the bigger picture Data Minded guides organizations through the phases of design, development and implementation. 5. Data Literacy Having the tools, and processes is one thing. Adoption throughout the organization can only happen if people are proficient with them.    Different roles require different levels of knowledge and experience. Data Minded helps data engineers, data scientists, and data analysts learn the correct fundamentals and grasp more advanced concepts through our Data Minded Academy. Consulting Conveyor Product & Features Comparison Docs Academy Our offering Resources Cases Blog About us Team Join us Cloud Partnerships Pricing Vismarkt 17, 3000 Leuven, Belgium info@dataminded.be Vat. BE.0667.976.246 Consulting Conveyor Academy Resources About us More Scale your Artificial Intelligence projects from proofs-of-concept to production systems with MLOps MLOps is a set of practices that aims to deploy and maintain machine learning models in production reliably and efficiently. The word is a compound of “Machine Learning (ML)” and “DevOps”, a systemic approach of collaboration between software development and operational teams. The intrinsic goal of MLOps is to bring DevOps culture, processes, and tools right into the scope of machine learning practitioners.  A well-implemented practice of MLOps will enable your business to design, build and manage reproducible, testable, and evolvable ML-powered software. You should use it as a general tool to prioritize improvements in how your organization leverages AI & ML through its business. Adopting these principles will result in strategic edges like, among others, a decreased time to production for your use cases, and an increased product uptime for your deployed systems. 

MLOps is a concept that stimulates a lot of reflections these days. A few interesting works to refer to for further investigations could be the Google Cloud or Microsoft Azure resources about MLOps implementations. The MLOps reference website is also an interesting resource. Machine learning is hard. Building and maintaining systems embedding machine learning is even harder. Modern artificial intelligence requires way more than Data Science code to deliver value to your business. Provisioning a serving infrastructure, collecting and maintaining datasets, automating models training and deployments, monitoring the resulting predictions and insights… All these capabilities are unavoidable steps in your journey to machine learning at scale. On top of specific capabilities requirements, the rise of machine learning in modern IT stacks highlighted clear challenges for artificial intelligence developers. How to experiment with data in a quick and structured way keeping track of produced models and datasets? How to maintain symmetry between experimental and operational environments? In an ever-evolving world, how to keep our models relevant against new realities? Are you ready to start your MLOps journey? Good. In this journey, challenges are ahead and will be numerous but, at Data Minded, we will keep you covered. Implementing MLOps will challenge the way your organization and its whole IT stack are operating. Enabling data-driven use cases will require you to reconsider your organization's culture, people skillset, delivery methodologies, and general perception of data & AI. Sounds daunting, no? The good news is that building data platforms is our specialty at Data Minded. We already did it for clients from various industries and, there are good chances we are busy building new ones at the moment you will read these lines. Our experience put us in good position to help your organization making the transition from thinking about AI as a source of innovation to a critical source of business value. We can help you in all those tough decision-making processes involving people, platforms, implementations, and processes. You’d like to read concrete examples? Gotcha, follow along!   A machine learning project always starts from a good question that is instantiated from business challenges. Therefore, we will start together by defining what are the use cases that are worth living (and growing) in your AI portfolio. We will also aim to define what kind of business value you want to unlock and what are the key metrics associated. Our common goals are clearer? Perfect! Time to kickstart a project! On a day-to-day basis, we will help your teams to focus on iteratively answering your challenging business questions through researches and technical implementations.   Industrializing machine learning models is all about building a scalable and sustainable foundation. This requires bringing structure and standardizing your way of working. We will define, along with your engineering teams, how architecture components like CI/CD pipelines, model stores, feature stores, monitoring applications, or experimentation platforms will embed in your existing IT stacks. We will also help you building shareable organization-specific AI & ML template projects to speed-up the delivery of new use cases.   We don’t want your data platform and the DataOps/MLOps processes running there to become the Wild West of your IT department.  Count on us to help you framing the governance and lifecycle of the various projects built by your ML engineers. Down the road, you will only get more efficient, organized, and reliable!  Consulting Conveyor Product & Features Comparison Docs Academy Our offering Resources Cases Blog About us Team Join us Cloud Partnerships Pricing Vismarkt 17, 3000 Leuven, Belgium info@dataminded.be Vat. BE.0667.976.246 Consulting Conveyor Academy Resources About us More Looks like something went wrong.  Consulting Conveyor Product & Features Comparison Docs Academy Our offering Resources Cases Blog About us Team Join us Cloud Partnerships Pricing Vismarkt 17, 3000 Leuven, Belgium info@dataminded.be Vat. BE.0667.976.246
generate_ngrams: 
[('consulting conveyor', 58), ('about us', 58), ('data minded', 50), ('of the', 32), ('academy our', 30), ('dataminded be', 30), ('conveyor academy', 29), ('academy resources', 29), ('resources about', 29), ('us more', 29), ('conveyor product', 29), ('product features', 29), ('features comparison', 29), ('comparison docs', 29), ('docs academy', 29), ('our offering', 29), ('offering resources', 29), ('resources cases', 29), ('cases blog', 29), ('blog about', 29)]
None
generate_ngrams: 
[('consulting conveyor', 56), ('about us', 56), ('data minded', 49), ('of the', 32), ('academy our', 29), ('dataminded be', 29), ('conveyor academy', 28), ('academy resources', 28), ('resources about', 28), ('us more', 28), ('conveyor product', 28), ('product features', 28), ('features comparison', 28), ('comparison docs', 28), ('docs academy', 28), ('our offering', 28), ('offering resources', 28), ('resources cases', 28), ('cases blog', 28), ('blog about', 28)]
None
